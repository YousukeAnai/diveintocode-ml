{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題1】公式Exampleを分担して実行¶\n",
    "TensorFLowの公式Exampleを分担して実行してください。\n",
    "以下の中から1人ひとつ選び実行し、その結果を簡単に発表してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anai\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tutorials → Build a Convolutional Neural Network using Estimators\n",
    "\n",
    "このexampleはtensorflowを使って2次元のCNNを作成している\n",
    "以下サンプルコードとコードリーティング結果を示す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "  \"\"\"Model function for CNN.\"\"\"\n",
    "  # Input Layer\n",
    "  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)  \n",
    "\n",
    "  # Pooling Layer #1\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Convolutional Layer #2 and Pooling Layer #2\n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Dense Layer\n",
    "  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits Layer\n",
    "  logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "  predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode)\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])\n",
    "  }\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データの整形や畳み込み層などをテンソルとして保存している\n",
    "結果をpredictionsという辞書を用いて格納している\n",
    "dropoutを指定し過学習を防いでいる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Estimator\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.estimator.Estimatorを使ってモデルのインスタンスを作成している\n",
    "model_fn引数に先ほどの関数を指定することで、任意のモデルを作成している"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data},\n",
    "    y=train_labels,\n",
    "    batch_size=100,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "# train one step and display the probabilties\n",
    "mnist_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=1,\n",
    "    hooks=[logging_hook])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データをestimator.inputs.numpy_input_fnで準備\n",
    "先ほど作成したクラス.trainで学習している\n",
    "input_fnには準備したデータを入力している"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data},\n",
    "    y=eval_labels,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validationデータを準備している\n",
    "先ほどのクラス.evaluateで推定している\n",
    "\n",
    "実行結果(google colaboratoryで実行しました)\n",
    "INFO:tensorflow:Calling model_fn. INFO:tensorflow:Done calling model_fn. INFO:tensorflow:Starting evaluation at 2019-09-15T06:23:32Z INFO:tensorflow:Graph was finalized. INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model/model.ckpt-2002 INFO:tensorflow:Running local_init_op. INFO:tensorflow:Done running local_init_op. INFO:tensorflow:Finished evaluation at 2019-09-15-06:23:39 INFO:tensorflow:Saving dict for global step 2002: accuracy = 0.848, global_step = 2002, loss = 0.6666925 INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2002: /tmp/mnist_convnet_model/model.ckpt-2002 {'accuracy': 0.848, 'loss': 0.6666925, 'global_step': 2002}\n",
    "\n",
    "最終的な正解率および損失\n",
    "{'accuracy': 0.8551, 'loss': 0.6025994, 'global_step': 2002}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 問題2】Iris（2値分類）をKerasで学習¶\n",
    "TensorFlowによるIrisデータセットに対する2値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1030 11:14:52.860879 17208 deprecation.py:506] From C:\\Users\\anai\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1030 11:14:52.978695 17208 deprecation.py:323] From C:\\Users\\anai\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                250       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 5,451\n",
      "Trainable params: 5,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 64 samples, validate on 16 samples\n",
      "Epoch 1/10\n",
      "64/64 - 0s - loss: 0.9593 - acc: 0.4688 - val_loss: 0.8827 - val_acc: 0.3750\n",
      "Epoch 2/10\n",
      "64/64 - 0s - loss: 0.7812 - acc: 0.5312 - val_loss: 0.7097 - val_acc: 0.3750\n",
      "Epoch 3/10\n",
      "64/64 - 0s - loss: 0.6515 - acc: 0.6875 - val_loss: 0.6308 - val_acc: 0.8750\n",
      "Epoch 4/10\n",
      "64/64 - 0s - loss: 0.6214 - acc: 0.8281 - val_loss: 0.6388 - val_acc: 0.4375\n",
      "Epoch 5/10\n",
      "64/64 - 0s - loss: 0.5787 - acc: 0.6094 - val_loss: 0.5694 - val_acc: 0.8125\n",
      "Epoch 6/10\n",
      "64/64 - 0s - loss: 0.5406 - acc: 0.8750 - val_loss: 0.4905 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "64/64 - 0s - loss: 0.4579 - acc: 0.8125 - val_loss: 0.3815 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "64/64 - 0s - loss: 0.4646 - acc: 0.8125 - val_loss: 0.5594 - val_acc: 0.5625\n",
      "Epoch 9/10\n",
      "64/64 - 0s - loss: 0.4287 - acc: 0.7969 - val_loss: 0.2753 - val_acc: 0.9375\n",
      "Epoch 10/10\n",
      "64/64 - 0s - loss: 0.2905 - acc: 0.9219 - val_loss: 0.2390 - val_acc: 1.0000\n",
      "y_pred [0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 1 0 1 0]\n",
      "Test loss: 0.31196102499961853\n",
      "Test accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "th.kerasで実装したニューラルネットワークを使いIrisデータセットを2値分類する\n",
    "\"\"\"\n",
    "# データセットの読み込み\n",
    "#dataset_path = r\"Iris.csv\"\n",
    "df = pd.read_csv(r\"C:\\Users\\anai\\dive\\Dataset\\iris\\iris.csv\")\n",
    "# データフレームから条件抽出\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "y = y.astype(np.int)[:, np.newaxis]\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 1\n",
    "\n",
    "input_data = tf.keras.layers.Input(shape=(n_input,))\n",
    "x = tf.keras.layers.Dense(n_hidden1, activation=tf.nn.relu)(input_data)\n",
    "x = tf.keras.layers.Dense(n_hidden2, activation=tf.nn.relu)(x)\n",
    "output = tf.keras.layers.Dense(n_classes, activation=tf.nn.sigmoid)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=10,\n",
    "                    epochs=10,\n",
    "                    verbose=2,\n",
    "                   validation_data=(X_val, y_val))\n",
    "\n",
    "y_pred_proba = model.predict(X_test)[:, 0]\n",
    "\n",
    "# 確率を0, 1に変換\n",
    "y_pred = np.where(y_pred_proba >0.5, 1, 0)\n",
    "\n",
    "#print(\"y_pred_proba\", y_pred_proba)\n",
    "print(\"y_pred\", y_pred)\n",
    "#結果がいらず、評価のみ行う場合はevaluateメソッドも便利です。\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題3】Iris（多値分類）をKerasで学習\n",
    "TensorFlowによるIrisデータセットに対する3値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                250       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 5,653\n",
      "Trainable params: 5,653\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 96 samples, validate on 24 samples\n",
      "Epoch 1/10\n",
      "96/96 - 0s - loss: 1.0413 - acc: 0.4792 - val_loss: 0.6270 - val_acc: 0.7083\n",
      "Epoch 2/10\n",
      "96/96 - 0s - loss: 0.5178 - acc: 0.7917 - val_loss: 0.3977 - val_acc: 0.7917\n",
      "Epoch 3/10\n",
      "96/96 - 0s - loss: 0.3612 - acc: 0.7708 - val_loss: 0.2953 - val_acc: 0.9167\n",
      "Epoch 4/10\n",
      "96/96 - 0s - loss: 0.2416 - acc: 0.8854 - val_loss: 0.2705 - val_acc: 0.9167\n",
      "Epoch 5/10\n",
      "96/96 - 0s - loss: 0.1436 - acc: 0.9583 - val_loss: 0.2821 - val_acc: 0.8750\n",
      "Epoch 6/10\n",
      "96/96 - 0s - loss: 0.2562 - acc: 0.8854 - val_loss: 0.1902 - val_acc: 0.9167\n",
      "Epoch 7/10\n",
      "96/96 - 0s - loss: 0.1547 - acc: 0.9479 - val_loss: 0.2312 - val_acc: 0.8333\n",
      "Epoch 8/10\n",
      "96/96 - 0s - loss: 0.1082 - acc: 0.9688 - val_loss: 0.2285 - val_acc: 0.8333\n",
      "Epoch 9/10\n",
      "96/96 - 0s - loss: 0.1152 - acc: 0.9583 - val_loss: 0.2021 - val_acc: 0.9167\n",
      "Epoch 10/10\n",
      "96/96 - 0s - loss: 0.0900 - acc: 0.9688 - val_loss: 0.2090 - val_acc: 0.9167\n",
      "y_pred_proba [[6.27998588e-07 3.16208019e-03 9.96837258e-01]\n",
      " [2.28335150e-03 9.90208626e-01 7.50791375e-03]\n",
      " [9.99800384e-01 1.99684204e-04 3.87286175e-10]\n",
      " [4.14158251e-07 1.34675112e-02 9.86532152e-01]\n",
      " [9.99037147e-01 9.62866412e-04 7.46502149e-09]\n",
      " [9.96656269e-08 1.43724179e-03 9.98562634e-01]\n",
      " [9.99205530e-01 7.94546504e-04 6.72564227e-09]\n",
      " [1.02597673e-03 9.70163524e-01 2.88105458e-02]\n",
      " [6.11332594e-04 9.59432185e-01 3.99564914e-02]\n",
      " [3.52366711e-03 9.89964068e-01 6.51234109e-03]\n",
      " [6.28215821e-06 4.13473025e-02 9.58646476e-01]\n",
      " [1.83272525e-03 9.74823177e-01 2.33441144e-02]\n",
      " [1.10373017e-03 9.36516941e-01 6.23793490e-02]\n",
      " [7.94880674e-04 9.16690409e-01 8.25147182e-02]\n",
      " [8.91525182e-04 8.35768282e-01 1.63340256e-01]\n",
      " [9.98648345e-01 1.35171041e-03 1.07548574e-08]\n",
      " [1.12301728e-03 8.19411278e-01 1.79465726e-01]\n",
      " [1.43726333e-03 8.15577865e-01 1.82984903e-01]\n",
      " [9.97856200e-01 2.14383076e-03 3.52858862e-08]\n",
      " [9.99593914e-01 4.06075182e-04 1.69953518e-09]\n",
      " [3.93343771e-06 9.38598905e-03 9.90610063e-01]\n",
      " [1.11904519e-03 6.26861274e-01 3.72019678e-01]\n",
      " [9.98202562e-01 1.79737376e-03 3.01762633e-08]\n",
      " [9.97386396e-01 2.61347997e-03 7.90751358e-08]\n",
      " [8.18460976e-05 1.75457805e-01 8.24460387e-01]\n",
      " [9.99445379e-01 5.54626575e-04 6.51730936e-09]\n",
      " [9.98875558e-01 1.12446013e-03 1.51871973e-08]\n",
      " [2.28592986e-03 9.86245990e-01 1.14681209e-02]\n",
      " [1.17472569e-02 9.81262743e-01 6.99005276e-03]\n",
      " [9.98431742e-01 1.56825897e-03 2.31775061e-08]]\n",
      "y_pred [[0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]]\n",
      "Test loss: 0.054277192801237106\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TensorFlowで実装したニューラルネットワークを使いIrisデータセットを3値分類する\n",
    "\"\"\"\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import sklearn.preprocessing as sp\n",
    "\n",
    "# データセットの読み込み\n",
    "#dataset_path = r\"Iris.csv\"\n",
    "df = pd.read_csv(r\"C:\\Users\\anai\\dive\\Dataset\\iris\\iris.csv\", delimiter=',')\n",
    "# データフレームから条件抽出\n",
    "#df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df['Species']\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-setosa'] = 0\n",
    "y[y=='Iris-versicolor'] = 1\n",
    "y[y=='Iris-virginica'] = 2\n",
    "\n",
    "#onehot\n",
    "#enc = OneHotEncoder(handle_unknown='ignore', sparse=False, dtype='int', categories='auto')\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False, dtype='int')\n",
    "y_1hot = enc.fit_transform(y[:, np.newaxis])\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_1hot, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 3\n",
    "\n",
    "\n",
    "input_data = tf.keras.layers.Input(shape=(n_input,))\n",
    "x = tf.keras.layers.Dense(n_hidden1, activation=tf.nn.relu)(input_data)\n",
    "x = tf.keras.layers.Dense(n_hidden2, activation=tf.nn.relu)(x)\n",
    "output = tf.keras.layers.Dense(n_classes, activation=tf.nn.softmax)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=10,\n",
    "                    epochs=10,\n",
    "                    verbose=2,\n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "y_pred_proba = model.predict(X_test)[:,:]\n",
    "\n",
    "# 確率を0, 1に変換\n",
    "y_pred = np.where(y_pred_proba >0.5, 1, 0)\n",
    "\n",
    "print(\"y_pred_proba\", y_pred_proba)\n",
    "print(\"y_pred\", y_pred)\n",
    "#結果がいらず、評価のみ行う場合はevaluateメソッドも便利です。\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題4】House PricesをKerasで学習\n",
    "TensorFlowによるHouse Pricesデータセットに対する回帰をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 50)                150       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 5,351\n",
      "Trainable params: 5,351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 934 samples, validate on 234 samples\n",
      "Epoch 1/10\n",
      "934/934 - 0s - loss: 37206157114.6552 - mean_squared_error: 37206171648.0000 - val_loss: 28063671348.5128 - val_mean_squared_error: 28063674368.0000\n",
      "Epoch 2/10\n",
      "934/934 - 0s - loss: 9594072866.6724 - mean_squared_error: 9594072064.0000 - val_loss: 3173902906.5299 - val_mean_squared_error: 3173902848.0000\n",
      "Epoch 3/10\n",
      "934/934 - 0s - loss: 3849478057.3876 - mean_squared_error: 3849477888.0000 - val_loss: 3074158268.7179 - val_mean_squared_error: 3074158592.0000\n",
      "Epoch 4/10\n",
      "934/934 - 0s - loss: 3678455904.8908 - mean_squared_error: 3678456320.0000 - val_loss: 3139821401.7094 - val_mean_squared_error: 3139821312.0000\n",
      "Epoch 5/10\n",
      "934/934 - 0s - loss: 3594885973.5503 - mean_squared_error: 3594885888.0000 - val_loss: 2943126263.7949 - val_mean_squared_error: 2943126272.0000\n",
      "Epoch 6/10\n",
      "934/934 - 0s - loss: 3456347002.7923 - mean_squared_error: 3456347392.0000 - val_loss: 2704048141.1282 - val_mean_squared_error: 2704048384.0000\n",
      "Epoch 7/10\n",
      "934/934 - 0s - loss: 3415192338.2955 - mean_squared_error: 3415191808.0000 - val_loss: 2654314245.4701 - val_mean_squared_error: 2654313984.0000\n",
      "Epoch 8/10\n",
      "934/934 - 0s - loss: 3298273849.4904 - mean_squared_error: 3298274304.0000 - val_loss: 2701303859.9658 - val_mean_squared_error: 2701304064.0000\n",
      "Epoch 9/10\n",
      "934/934 - 0s - loss: 3281288010.2784 - mean_squared_error: 3281287680.0000 - val_loss: 2645944482.4615 - val_mean_squared_error: 2645944576.0000\n",
      "Epoch 10/10\n",
      "934/934 - 0s - loss: 3227860314.4839 - mean_squared_error: 3227860224.0000 - val_loss: 2964597909.8803 - val_mean_squared_error: 2964598272.0000\n",
      "y_pred_proba [[294904.94 ]\n",
      " [205188.98 ]\n",
      " [169641.56 ]\n",
      " [248539.4  ]\n",
      " [159624.12 ]\n",
      " [151224.89 ]\n",
      " [196174.17 ]\n",
      " [185709.88 ]\n",
      " [481870.8  ]\n",
      " [161505.27 ]\n",
      " [185449.62 ]\n",
      " [215902.22 ]\n",
      " [245443.1  ]\n",
      " [141190.5  ]\n",
      " [158023.48 ]\n",
      " [180444.31 ]\n",
      " [239525.55 ]\n",
      " [150523.98 ]\n",
      " [172479.14 ]\n",
      " [228105.3  ]\n",
      " [187086.14 ]\n",
      " [137285.44 ]\n",
      " [133082.2  ]\n",
      " [197431.9  ]\n",
      " [234536.33 ]\n",
      " [219164.9  ]\n",
      " [206375.23 ]\n",
      " [115825.51 ]\n",
      " [218492.48 ]\n",
      " [170799.61 ]\n",
      " [224549.36 ]\n",
      " [225440.55 ]\n",
      " [142643.22 ]\n",
      " [265964.4  ]\n",
      " [251702.08 ]\n",
      " [194146.5  ]\n",
      " [205371.88 ]\n",
      " [139618.34 ]\n",
      " [256136.17 ]\n",
      " [306127.6  ]\n",
      " [260740.17 ]\n",
      " [184783.58 ]\n",
      " [181408.34 ]\n",
      " [231567.56 ]\n",
      " [322475.72 ]\n",
      " [220141.23 ]\n",
      " [133713.02 ]\n",
      " [140873.48 ]\n",
      " [216244.66 ]\n",
      " [143453.2  ]\n",
      " [310754.6  ]\n",
      " [157640.48 ]\n",
      " [182916.31 ]\n",
      " [129801.55 ]\n",
      " [212835.69 ]\n",
      " [138638.3  ]\n",
      " [190392.27 ]\n",
      " [228258.17 ]\n",
      " [162170.77 ]\n",
      " [130097.03 ]\n",
      " [155769.03 ]\n",
      " [154999.42 ]\n",
      " [172991.14 ]\n",
      " [165160.97 ]\n",
      " [216314.23 ]\n",
      " [196103.75 ]\n",
      " [143545.12 ]\n",
      " [217976.72 ]\n",
      " [173010.7  ]\n",
      " [221717.33 ]\n",
      " [193034.67 ]\n",
      " [157293.31 ]\n",
      " [144955.16 ]\n",
      " [191877.84 ]\n",
      " [146591.7  ]\n",
      " [213505.61 ]\n",
      " [150486.17 ]\n",
      " [143477.45 ]\n",
      " [291244.34 ]\n",
      " [179494.   ]\n",
      " [144984.08 ]\n",
      " [138074.44 ]\n",
      " [182277.84 ]\n",
      " [150523.98 ]\n",
      " [348730.97 ]\n",
      " [183932.2  ]\n",
      " [169711.02 ]\n",
      " [186950.44 ]\n",
      " [172156.28 ]\n",
      " [158112.92 ]\n",
      " [216713.05 ]\n",
      " [205794.12 ]\n",
      " [199081.95 ]\n",
      " [233895.19 ]\n",
      " [176467.61 ]\n",
      " [174699.69 ]\n",
      " [197999.31 ]\n",
      " [213695.2  ]\n",
      " [137848.61 ]\n",
      " [204402.14 ]\n",
      " [221869.06 ]\n",
      " [239740.3  ]\n",
      " [182928.7  ]\n",
      " [191703.12 ]\n",
      " [123053.59 ]\n",
      " [286569.22 ]\n",
      " [186040.58 ]\n",
      " [145170.78 ]\n",
      " [198027.42 ]\n",
      " [183154.03 ]\n",
      " [120184.305]\n",
      " [153324.34 ]\n",
      " [245605.84 ]\n",
      " [161210.98 ]\n",
      " [194803.67 ]\n",
      " [203314.75 ]\n",
      " [284535.5  ]\n",
      " [154431.45 ]\n",
      " [259723.36 ]\n",
      " [243352.8  ]\n",
      " [159403.3  ]\n",
      " [189299.81 ]\n",
      " [149407.16 ]\n",
      " [244091.39 ]\n",
      " [207777.45 ]\n",
      " [197567.   ]\n",
      " [258794.42 ]\n",
      " [180576.39 ]\n",
      " [174843.19 ]\n",
      " [200930.75 ]\n",
      " [184432.78 ]\n",
      " [174747.66 ]\n",
      " [269374.   ]\n",
      " [193152.16 ]\n",
      " [137848.61 ]\n",
      " [216522.34 ]\n",
      " [196673.78 ]\n",
      " [184994.7  ]\n",
      " [140918.73 ]\n",
      " [209010.55 ]\n",
      " [164768.33 ]\n",
      " [158667.02 ]\n",
      " [270450.22 ]\n",
      " [154824.16 ]\n",
      " [175429.86 ]\n",
      " [199311.7  ]\n",
      " [196365.11 ]\n",
      " [155561.31 ]\n",
      " [223585.53 ]\n",
      " [198784.97 ]\n",
      " [191242.3  ]\n",
      " [218902.12 ]\n",
      " [228219.17 ]\n",
      " [263330.4  ]\n",
      " [213129.61 ]\n",
      " [321036.5  ]\n",
      " [162397.1  ]\n",
      " [199033.8  ]\n",
      " [163309.27 ]\n",
      " [197471.16 ]\n",
      " [137876.83 ]\n",
      " [168460.66 ]\n",
      " [206830.45 ]\n",
      " [146986.17 ]\n",
      " [206639.72 ]\n",
      " [198751.92 ]\n",
      " [194937.58 ]\n",
      " [279765.03 ]\n",
      " [185966.86 ]\n",
      " [217532.31 ]\n",
      " [187080.73 ]\n",
      " [204953.25 ]\n",
      " [181026.12 ]\n",
      " [164372.73 ]\n",
      " [149210.77 ]\n",
      " [161248.52 ]\n",
      " [163328.81 ]\n",
      " [304795.28 ]\n",
      " [179136.58 ]\n",
      " [158814.23 ]\n",
      " [259193.62 ]\n",
      " [238562.67 ]\n",
      " [160678.11 ]\n",
      " [219064.66 ]\n",
      " [136716.19 ]\n",
      " [221684.38 ]\n",
      " [149564.1  ]\n",
      " [172836.56 ]\n",
      " [190226.7  ]\n",
      " [137285.44 ]\n",
      " [150523.98 ]\n",
      " [184609.22 ]\n",
      " [202864.31 ]\n",
      " [143341.7  ]\n",
      " [173145.73 ]\n",
      " [151485.5  ]\n",
      " [115825.51 ]\n",
      " [163654.95 ]\n",
      " [218940.55 ]\n",
      " [185710.2  ]\n",
      " [182861.22 ]\n",
      " [173096.16 ]\n",
      " [128835.47 ]\n",
      " [154852.22 ]\n",
      " [237857.64 ]\n",
      " [306551.9  ]\n",
      " [174620.77 ]\n",
      " [261675.17 ]\n",
      " [226810.39 ]\n",
      " [136267.81 ]\n",
      " [162651.81 ]\n",
      " [213908.64 ]\n",
      " [154066.78 ]\n",
      " [128936.625]\n",
      " [231491.4  ]\n",
      " [282310.47 ]\n",
      " [190271.   ]\n",
      " [316149.75 ]\n",
      " [214459.19 ]\n",
      " [115883.125]\n",
      " [196179.22 ]\n",
      " [188204.06 ]\n",
      " [209750.67 ]\n",
      " [137905.06 ]\n",
      " [200126.69 ]\n",
      " [251560.95 ]\n",
      " [240990.66 ]\n",
      " [235455.16 ]\n",
      " [173103.33 ]\n",
      " [186328.2  ]\n",
      " [154038.7  ]\n",
      " [162751.27 ]\n",
      " [137876.83 ]\n",
      " [160966.19 ]\n",
      " [232620.7  ]\n",
      " [189298.61 ]\n",
      " [226526.11 ]\n",
      " [134446.27 ]\n",
      " [164908.55 ]\n",
      " [196188.27 ]\n",
      " [177297.25 ]\n",
      " [216073.73 ]\n",
      " [225789.62 ]\n",
      " [226715.03 ]\n",
      " [176008.42 ]\n",
      " [159662.72 ]\n",
      " [185597.06 ]\n",
      " [207346.2  ]\n",
      " [179394.22 ]\n",
      " [192798.7  ]\n",
      " [191511.8  ]\n",
      " [241445.89 ]\n",
      " [136493.62 ]\n",
      " [337103.88 ]\n",
      " [181902.75 ]\n",
      " [231567.56 ]\n",
      " [137333.25 ]\n",
      " [206191.11 ]\n",
      " [368669.47 ]\n",
      " [592686.8  ]\n",
      " [222176.73 ]\n",
      " [198676.34 ]\n",
      " [226248.47 ]\n",
      " [176934.61 ]\n",
      " [255295.89 ]\n",
      " [225033.33 ]\n",
      " [313280.84 ]\n",
      " [104272.62 ]\n",
      " [250718.08 ]\n",
      " [218139.23 ]\n",
      " [194629.86 ]\n",
      " [252628.1  ]\n",
      " [198199.56 ]\n",
      " [207022.97 ]\n",
      " [266432.97 ]\n",
      " [255211.22 ]\n",
      " [223106.36 ]\n",
      " [220609.05 ]\n",
      " [242247.61 ]\n",
      " [181508.66 ]\n",
      " [140760.55 ]\n",
      " [245298.27 ]\n",
      " [197206.97 ]\n",
      " [203394.53 ]\n",
      " [179907.53 ]\n",
      " [258671.58 ]\n",
      " [171691.88 ]\n",
      " [220100.42 ]\n",
      " [285629.53 ]\n",
      " [294776.34 ]\n",
      " [122274.81 ]\n",
      " [160009.23 ]]\n",
      "Test loss: 4102116814.9041095\n",
      "Test accuracy: 4102116900.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TensorFlowで実装したニューラルネットワークを使いHouse Pricesデータセットの価格を推定する。\n",
    "\"\"\"\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# データセットの読み込み\n",
    "df = pd.read_csv(r\"C:\\Users\\anai\\dive\\Dataset\\House Prices\\train.csv\", delimiter=',')\n",
    "#df_test = pd.read_csv(r\"C:\\Users\\anai\\dive\\Dataset\\House Prices\\test.csv\", delimiter=',')\n",
    "\n",
    "# データフレームから条件抽出\n",
    "y = df['SalePrice']\n",
    "X = df.loc[:,[\"GrLivArea\", \"YearBuilt\"]]\n",
    "\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "#std = StandardScaler()\n",
    "#X_train = std.fit_transform(X_train)\n",
    "#X_test = std.fit_transform(X_test)\n",
    "#X_val = std.fit_transform(X_val)\n",
    "\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_val = y_val.reshape(-1, 1)\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.00000000001\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 1\n",
    "\n",
    "########\n",
    "\n",
    "input_data = tf.keras.layers.Input(shape=(n_input,))\n",
    "x = tf.keras.layers.Dense(n_hidden1, activation=tf.nn.relu)(input_data)\n",
    "x = tf.keras.layers.Dense(n_hidden2, activation=tf.nn.relu)(x)\n",
    "output = tf.keras.layers.Dense(n_classes)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=tf.train.GradientDescentOptimizer(learning_rate=learning_rate),\n",
    "              metrics=['mean_squared_error'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=10,\n",
    "                    epochs=10,\n",
    "                    verbose=2,\n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "y_pred_proba = model.predict(X_test)[:,:]\n",
    "\n",
    "# 確率を0, 1に変換\n",
    "#y_pred = np.where(y_pred_proba >0.5, 1, 0)\n",
    "\n",
    "print(\"y_pred_proba\", y_pred_proba)\n",
    "#print(\"y_pred\", y_pred)\n",
    "#結果がいらず、評価のみ行う場合はevaluateメソッドも便利です。\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題5】MNISTをKerasで学習\n",
    "TensorFlowによるMNISTデータセットによる画像の多値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 45,360\n",
      "Trainable params: 45,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 38400 samples, validate on 9600 samples\n",
      "Epoch 1/10\n",
      "38400/38400 - 1s - loss: 0.2990 - acc: 0.9090 - val_loss: 0.2055 - val_acc: 0.9364\n",
      "Epoch 2/10\n",
      "38400/38400 - 1s - loss: 0.1604 - acc: 0.9504 - val_loss: 0.1631 - val_acc: 0.9502\n",
      "Epoch 3/10\n",
      "38400/38400 - 1s - loss: 0.1304 - acc: 0.9592 - val_loss: 0.1505 - val_acc: 0.9584\n",
      "Epoch 4/10\n",
      "38400/38400 - 1s - loss: 0.1141 - acc: 0.9657 - val_loss: 0.1524 - val_acc: 0.9577\n",
      "Epoch 5/10\n",
      "38400/38400 - 1s - loss: 0.1028 - acc: 0.9688 - val_loss: 0.1534 - val_acc: 0.9588\n",
      "Epoch 6/10\n",
      "38400/38400 - 1s - loss: 0.1077 - acc: 0.9693 - val_loss: 0.1820 - val_acc: 0.9518\n",
      "Epoch 7/10\n",
      "38400/38400 - 1s - loss: 0.0854 - acc: 0.9741 - val_loss: 0.1800 - val_acc: 0.9593\n",
      "Epoch 8/10\n",
      "38400/38400 - 1s - loss: 0.0939 - acc: 0.9721 - val_loss: 0.1994 - val_acc: 0.9543\n",
      "Epoch 9/10\n",
      "38400/38400 - 1s - loss: 0.0845 - acc: 0.9752 - val_loss: 0.2168 - val_acc: 0.9574\n",
      "Epoch 10/10\n",
      "38400/38400 - 1s - loss: 0.0806 - acc: 0.9762 - val_loss: 0.1884 - val_acc: 0.9564\n",
      "Test loss: 0.1983021905789307\n",
      "Test accuracy: 0.9544167\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TensorFlowで実装したニューラルネットワークを使いMNISTデータセットを3値分類する\n",
    "\"\"\"\n",
    "# データセットの読み込み\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 画像データを2次元に変換\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "#onehot\n",
    "enc = Oneenc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test = enc.fit_transform(y_test[:, np.newaxis])\n",
    "\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.05\n",
    "batch_size = 100\n",
    "num_epochs = 10\n",
    "\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 10\n",
    "\n",
    "\n",
    "input_data = tf.keras.layers.Input(shape=(n_input,))\n",
    "x = tf.keras.layers.Dense(n_hidden1, activation=tf.nn.relu)(input_data)\n",
    "x = tf.keras.layers.Dense(n_hidden2, activation=tf.nn.relu)(x)\n",
    "output = tf.keras.layers.Dense(n_classes, activation=tf.nn.softmax)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=100,\n",
    "                    epochs=10,\n",
    "                    verbose=2,\n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "y_pred_proba = model.predict(X_test)[:,:]\n",
    "\n",
    "# 確率を0, 1に変換\n",
    "y_pred = np.where(y_pred_proba >0.5, 1, 0)\n",
    "\n",
    "#print(\"y_pred_proba\", y_pred_proba)\n",
    "#print(\"y_pred\", y_pred)\n",
    "#結果がいらず、評価のみ行う場合はevaluateメソッドも便利です。\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
