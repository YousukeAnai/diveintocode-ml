{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sprint2 課題　機械学習スクラッチ入門¶\n",
    "\n",
    "#### 1.このSprintについて\n",
    "\n",
    "##### Sprintの目的\n",
    "機械学習スクラッチの準備をする ### どのように学ぶか 今後の機械学習スクラッチ課題で作成するモデルを、scikit-learnを用いて一度動かしておきます。これまでの復習を兼ねたスクラッチ課題の準備です。\n",
    "\n",
    "#### 2.スクラッチ\n",
    "このSprintでは機械学習手法のスクラッチ課題に取り組む準備を行います。scikit-learnを用いて分類・回帰問題を解くコードを書いておき、今後のSprintではそれと同じ動作をするクラスをスクラッチで作成していきます。\n",
    "\n",
    "##### スクラッチの意義\n",
    "ここでのスクラッチとは、NumPyなどの基本的なライブラリを組み合わせることで、scikit-learnのような応用的なライブラリと同じ機能のクラス・関数を自作することを指します。\n",
    "\n",
    "スクラッチをすることでscikit-learnなどのライブラリを動かすだけでは掴みづらい、アルゴリズムの深い理解を目指します。コーディングのスキル向上も兼ねますが、それは主な目的ではありません。\n",
    "\n",
    "以下のような効果を狙っています。\n",
    "\n",
    "新たな手法に出会った時に理論・数式を理解しやすくする\n",
    "ライブラリを使う上での曖昧さを減らす\n",
    "既存の実装を読みやすくする\n",
    "＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿\n",
    "\n",
    "### 【問題1】train_test_splitのスクラッチ \n",
    "スクラッチの練習として、scikit-learnのtrain_test_splitを自作してみます。以下の雛形をベースとして関数を完成させてください。\n",
    "\n",
    "sklearn.model_selection.train_test_split — scikit-learn 0.21.3 documentation\n",
    "\n",
    "なお、作成した関数がscikit-learnのtrain_test_splitと同じ動作をしているか必ず確認をするようにしましょう。\n",
    "\n",
    "雛形\n",
    "\n",
    "def scratch_train_test_split(X, y, train_size=0.8,):\n",
    "    \"\"\"\n",
    "    検証用データを分割する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "    y : 次の形のndarray, shape (n_samples, )\n",
    "      正解値\n",
    "    train_size : float (0<train_size<1)\n",
    "      何割をtrainとするか指定\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    X_train : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "    X_test : 次の形のndarray, shape (n_samples, n_features)\n",
    "      検証データ\n",
    "    y_train : 次の形のndarray, shape (n_samples, )\n",
    "      学習データの正解値\n",
    "    y_test : 次の形のndarray, shape (n_samples, )\n",
    "      検証データの正解値\n",
    "    \"\"\"\n",
    "    #ここにコードを書く\n",
    "    pass\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scratch_train_test_split(X, y, train_size=0.8):\n",
    "    \"\"\"\n",
    "    検証用データを分割する。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "    y : 次の形のndarray, shape (n_samples, )\n",
    "      正解値\n",
    "    train_size : float (0<train_size<1)\n",
    "      何割をtrainとするか指定\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    X_train : 次の形のndarray, shape (n_samples, n_features)\n",
    "      学習データ\n",
    "    X_test : 次の形のndarray, shape (n_samples, n_features)\n",
    "      検証データ\n",
    "    y_train : 次の形のndarray, shape (n_samples, )\n",
    "      学習データの正解値\n",
    "    y_test : 次の形のndarray, shape (n_samples, )\n",
    "      検証データの正解値\n",
    "    \"\"\"\n",
    "    y = y.reshape(-1,1)\n",
    "    z = np.concatenate([X,y],axis=1)\n",
    "    np.random.shuffle(z)\n",
    "    z_train, z_test = np.array_split(z, [int(len(z)*train_size)])\n",
    "    X_train = z_train[:,:-1]\n",
    "    y_train = z_train[:,-1].reshape(z_train.shape[0], 1)\n",
    "    X_test = z_test[:,:-1]\n",
    "    y_test = z_test[:,-1].reshape(z_test.shape[0], 1)    \n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2],\n",
       "       [ 3,  4,  5],\n",
       "       [ 6,  7,  8],\n",
       "       [ 9, 10, 11],\n",
       "       [12, 13, 14]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[5],\n",
       "       [6],\n",
       "       [3],\n",
       "       [7],\n",
       "       [9]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  5],\n",
       "       [ 3,  4,  5,  6],\n",
       "       [ 6,  7,  8,  3],\n",
       "       [ 9, 10, 11,  7],\n",
       "       [12, 13, 14,  9]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.arange(15).reshape(5,3)\n",
    "y = np.array([5,6,3,7,9])\n",
    "y = y.reshape(5,1)\n",
    "display(X)\n",
    "display(y)\n",
    "y.shape\n",
    "len(X)\n",
    "z = np.concatenate([X,y],axis=1)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "「Scratch」\n",
      "---Scratch_X_train---\n",
      "[[ 6  7  8]\n",
      " [ 9 10 11]\n",
      " [ 0  1  2]]\n",
      "---Scratch_y_train---\n",
      "[[3]\n",
      " [7]\n",
      " [5]]\n",
      "---Scratch_X_test---\n",
      "[[ 3  4  5]\n",
      " [12 13 14]]\n",
      "---Scratch_y_test---\n",
      "[[6]\n",
      " [9]]\n",
      "\n",
      "「Sklearn」\n",
      "---Sklearn_X_train---\n",
      "[[ 3  4  5]\n",
      " [ 9 10 11]\n",
      " [12 13 14]]\n",
      "---Sklearn_y_train---\n",
      "[[6]\n",
      " [7]\n",
      " [9]]\n",
      "---Sklearn_X_test---\n",
      "[[6 7 8]\n",
      " [0 1 2]]\n",
      "---Sklearn_y_test---\n",
      "[[3]\n",
      " [5]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X,y,0.6)\n",
    "print(\"\\n「Scratch」\")\n",
    "print(\"---Scratch_X_train---\\n{}\".format(X_train))\n",
    "print(\"---Scratch_y_train---\\n{}\".format(y_train))\n",
    "print(\"---Scratch_X_test---\\n{}\".format(X_test))\n",
    "print(\"---Scratch_y_test---\\n{}\".format(y_test))\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.4, \n",
    "                                                    random_state=0)\n",
    "print(\"\\n「Sklearn」\")\n",
    "print(\"---Sklearn_X_train---\\n{}\".format(X_train))\n",
    "print(\"---Sklearn_y_train---\\n{}\".format(y_train))\n",
    "print(\"---Sklearn_X_test---\\n{}\".format(X_test))\n",
    "print(\"---Sklearn_y_test---\\n{}\".format(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.scikit-learnを用いて機械学習を行うコードを作成\n",
    "scikit-learnを使ったコードを作成していきます。\n",
    "\n",
    "検証用データの分割には問題1で作成した自作の関数を用いてください。クロスバリデーションではなくホールドアウト法で構いません。\n",
    "\n",
    "##### 分類問題\n",
    "分類は3種類の手法をスクラッチします。\n",
    "\n",
    "    ロジスティック回帰\n",
    "    SVM\n",
    "    決定木\n",
    "ロジスティック回帰はscikit-learnにおいてLogisticRegressionクラスとSGDClassifierクラスの2種類から使用できます。ここでは勾配降下法を用いて計算するSGDClassifierクラスを利用してください。引数でloss=\"log\"とすることでロジスティック回帰の計算になります。\n",
    "\n",
    "    sklearn.linear_model.SGDClassifier — scikit-learn 0.21.3 documentation\n",
    "    sklearn.svm.SVC — scikit-learn 0.21.3 documentation\n",
    "    sklearn.tree.DecisionTreeClassifier — scikit-learn 0.21.3 documentation\n",
    "データセットは3種類用意します。\n",
    "\n",
    "1つ目は事前学習期間同様にirisデータセットです。\n",
    "\n",
    "sklearn.datasets.load_iris — scikit-learn 0.20.2 documentation\n",
    "\n",
    "2値分類としたいため、以下の2つの目的変数のみ利用します。特徴量は4種類全て使います。\n",
    "\n",
    "virgicolorとvirginica\n",
    "残り2つは特徴量が2つのデータセットを人工的に用意します。以下のコードで説明変数X,目的変数yが作成可能です。「シンプルデータセット1」「シンプルデータセット2」とします。特徴量が2つであるため可視化が容易です。\n",
    "\n",
    "シンプルデータセット1作成コード\n",
    "\n",
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0 = [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "\n",
    "f0 = np.random.multivariate_normal(f0, cov, int(n_samples/2))\n",
    "f1 = np.random.multivariate_normal(f1, cov, int(n_samples/2))\n",
    "\n",
    "X = np.concatenate((f0, f1))\n",
    "y = np.concatenate((np.ones((int(n_samples/2))), np.ones((int(n_samples/2))) *(-1))).astype(np.int)\n",
    "\n",
    "random_index = np.random.permutation(np.arange(n_samples))\n",
    "X = X[random_index]\n",
    "y = y[random_index]\n",
    "シンプルデータセット2作成コード\n",
    "\n",
    "X = np.array([[-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n",
    "       [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n",
    "       [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n",
    "       [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n",
    "       [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n",
    "       [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n",
    "       [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n",
    "       [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n",
    "       [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n",
    "       [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n",
    "       [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n",
    "       [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n",
    "       [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n",
    "       [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n",
    "       [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n",
    "       [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n",
    "       [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n",
    "       [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n",
    "       [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n",
    "       [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ]])\n",
    "y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿\n",
    "\n",
    "### 【問題2】 分類問題を解くコードの作成 \n",
    "分類は3種類の手法をスクラッチします。\n",
    "    ・ロジスティック回帰\n",
    "    ・SVM\n",
    "    ・決定木\n",
    "ロジスティック回帰はscikit-learnにおいてLogisticRegressionクラスとSGDClassifierクラスの2種類から使用できます。ここでは勾配降下法を用いて計算するSGDClassifierクラスを利用してください。引数でloss=\"log\"とすることでロジスティック回帰の計算になります。\n",
    "\n",
    "データセットは3種類用意します。\n",
    "1つ目は事前学習期間同様にirisデータセットです。\n",
    "2値分類としたいため、以下の2つの目的変数のみ利用します。特徴量は4種類全て使います。\n",
    "virgicolorとvirginica\n",
    "残り2つは特徴量が2つのデータセットを人工的に用意します。以下のコードで説明変数X,目的変数yが作成可能です。「シンプルデータセット1」「シンプルデータセット2」とします。特徴量が2つであるため可視化が容易です。\n",
    "上記3種類の手法で3種類のデータセットを学習・推定するコードを作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0 = [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "\n",
    "f0 = np.random.multivariate_normal(f0, cov, int(n_samples/2))\n",
    "f1 = np.random.multivariate_normal(f1, cov, int(n_samples/2))\n",
    "\n",
    "X = np.concatenate((f0, f1))\n",
    "y = np.concatenate((np.ones((int(n_samples/2))), np.ones((int(n_samples/2))) *(-1))).astype(np.int)\n",
    "\n",
    "random_index = np.random.permutation(np.arange(n_samples))\n",
    "X_data1 = X[random_index]\n",
    "y_data1 = y[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(40,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_data2 = np.array([[-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n",
    "       [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n",
    "       [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n",
    "       [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n",
    "       [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n",
    "       [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n",
    "       [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n",
    "       [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n",
    "       [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n",
    "       [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n",
    "       [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n",
    "       [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n",
    "       [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n",
    "       [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n",
    "       [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n",
    "       [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n",
    "       [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n",
    "       [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n",
    "       [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n",
    "       [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ]])\n",
    "y_data2 = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
    "display(X_data2.shape)\n",
    "display(y_data2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=[\"sepal_length\",\"sepal_width\",\"petal_length\",\"petal_width\"])\n",
    "y = pd.DataFrame(iris.target, columns=[\"target\"])\n",
    "\n",
    "X_iris = X.iloc[50:150, :]\n",
    "y_iris = y.iloc[50:150, :]\n",
    "y_iris -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def func_models_eval(_X_train, _y_train, _X_test, _y_test):\n",
    "\n",
    "    models = {\n",
    "         \"LogisticRegression\":SGDClassifier(loss=\"log\", random_state=0),\n",
    "        \n",
    "         \"SVC\":SVC(gamma=\"auto\"),\n",
    "\n",
    "         \"DecisionTree\":DecisionTreeClassifier(random_state=0),\n",
    "    }\n",
    "    \n",
    "    _df_results = pd.DataFrame()\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(_X_train, _y_train)\n",
    "        print(\"{}\".format(model_name))\n",
    "        display(model.predict(_X_test))\n",
    "        fpr, tpr, thresh = metrics.roc_curve(_y_test, model.predict(_X_test))\n",
    "        _df_result = pd.DataFrame({model_name:[accuracy_score(_y_test, model.predict(_X_test)), \n",
    "                                           precision_score(_y_test, model.predict(_X_test), average='micro'),\n",
    "                                           recall_score(_y_test, model.predict(_X_test), average='micro'),\n",
    "                                           f1_score(_y_test, model.predict(_X_test), average='micro'),\n",
    "                                           metrics.auc(fpr, tpr)]}, \n",
    "                                index=[\"accuracy_score\", \"precision_score\", \"recall_score\",\"f1_score\", \"auc_score\"])\n",
    "        _df_results = pd.concat([_df_results, _df_result],axis=1)                        \n",
    "                                \n",
    "#        print(\"confusion_matrix\")\n",
    "        print(\" {}\".format(confusion_matrix(_y_test, model.predict(_X_test)), average='macro'))        \n",
    "#        print(\"TRAIN_DATA\")\n",
    "#        decision_region(_X_train, _y_train, model, 0.01, model_name)\n",
    "#        print(\"TEST_DATA\")\n",
    "#        decision_region(_X_test, _y_test, model, 0.01, model_name)\n",
    "    return _df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def decision_region(X, y, model, step=0.01, title='decision region', xlabel='xlabel', ylabel='ylabel', target_names=['0', '1']):\n",
    "    \"\"\"\n",
    "    2値分類を2次元の特徴量で学習したモデルの決定領域を描く。\n",
    "    背景の色が学習したモデルによる推定値から描画される。\n",
    "    散布図の点は訓練データまたは検証データである。\n",
    "\n",
    "    Parameters\n",
    "    ----------------\n",
    "    X : ndarray, shape(n_samples, 2)\n",
    "        特徴量\n",
    "    y : ndarray, shape(n_samples,)\n",
    "        ラベル\n",
    "    model : object\n",
    "        学習したモデルのインスタンスを入れる\n",
    "    step : float, (default : 0.1)\n",
    "        推定値を計算する間隔を設定する\n",
    "    title : str\n",
    "        グラフのタイトルの文章を与える\n",
    "    xlabel, ylabel : str\n",
    "        軸ラベルの文章を与える\n",
    "    target_names= : list of str\n",
    "        凡例の一覧を与える\n",
    "    \"\"\"\n",
    "    # setting\n",
    "    scatter_color = ['red', 'blue']\n",
    "    contourf_color = ['pink', 'skyblue']\n",
    "    n_class = 2\n",
    "\n",
    "    # pred\n",
    "    mesh_f0, mesh_f1  = np.meshgrid(np.arange(np.min(X[:,0])-0.5, np.max(X[:,0])+0.5, step), \n",
    "                                    np.arange(np.min(X[:,1])-0.5, np.max(X[:,1])+0.5, step))\n",
    "    mesh = np.c_[np.ravel(mesh_f0),np.ravel(mesh_f1)]\n",
    "    y_pred = model.predict(mesh).reshape(mesh_f0.shape)\n",
    "\n",
    "    # plot\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.contourf(mesh_f0, mesh_f1, y_pred, n_class-1, cmap=ListedColormap(contourf_color))\n",
    "    plt.contour(mesh_f0, mesh_f1, y_pred, n_class-1, colors='y', linewidths=3, alpha=0.5)\n",
    "    for i, target in enumerate(set(y)):\n",
    "        plt.scatter(X[y==target][:, 0], X[y==target][:, 1], s=80, color=scatter_color[i], label=target_names[i], marker='o')\n",
    "    patches = [mpatches.Patch(color=scatter_color[i], label=target_names[i]) for i in range(n_class)]\n",
    "    plt.legend(handles=patches)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std = StandardScaler()\n",
    "def src_standard_scaler(X,y):\n",
    "    X_train, X_test, y_train, y_test = scratch_train_test_split(X, y)\n",
    "    X_train_std = std.fit_transform(X_train)\n",
    "    X_test_std = std.fit_transform(X_test)\n",
    "    return X_train_std, y_train, X_test_std ,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris_Dataset\n",
      "LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anai\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\anai\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 1.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [[12  0]\n",
      " [ 0  8]]\n",
      "SVC\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 1.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [[12  0]\n",
      " [ 0  8]]\n",
      "DecisionTree\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 1.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [[11  1]\n",
      " [ 0  8]]\n",
      "Simple_Dataset1\n",
      "LogisticRegression\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,\n",
       "       -1., -1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,  1.,  1., -1.,\n",
       "       -1., -1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1., -1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "        1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1., -1.,\n",
       "       -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,\n",
       "       -1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "       -1., -1.,  1., -1., -1., -1., -1.,  1.,  1.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [[47  0]\n",
      " [ 0 53]]\n",
      "SVC\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,\n",
       "       -1., -1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,  1.,  1., -1.,\n",
       "       -1., -1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1., -1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "        1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1., -1.,\n",
       "       -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,\n",
       "       -1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "       -1., -1.,  1., -1., -1., -1., -1.,  1.,  1.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [[47  0]\n",
      " [ 0 53]]\n",
      "DecisionTree\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,\n",
       "       -1., -1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,  1.,  1., -1.,\n",
       "       -1., -1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,  1.,\n",
       "        1., -1., -1., -1.,  1., -1.,  1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "        1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1., -1.,\n",
       "       -1.,  1.,  1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,\n",
       "       -1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "       -1., -1.,  1., -1., -1., -1., -1.,  1.,  1.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [[47  0]\n",
      " [ 0 53]]\n",
      "Simple_Dataset2\n",
      "LogisticRegression\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 1., 1., 1., 1., 0.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [[1 5]\n",
      " [1 1]]\n",
      "SVC\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 1., 1., 1., 1., 0.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [[2 4]\n",
      " [1 1]]\n",
      "DecisionTree\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 1., 1., 1.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [[3 3]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "datasets = {\n",
    "    \"Iris_Dataset\":[X_iris.values, y_iris.values],\n",
    "    \"Simple_Dataset1\":[X_data1, y_data1],\n",
    "    \"Simple_Dataset2\":[X_data2, y_data2]\n",
    "    }\n",
    "for data_name, data in datasets.items():\n",
    "    X_train_std, y_train, X_test_std ,y_test = src_standard_scaler(data[0], data[1])\n",
    "    print(data_name)\n",
    "    func_models_eval(X_train_std, y_train, X_test_std ,y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 回帰問題\n",
    "回帰は1種類をスクラッチします。\n",
    "\n",
    "線形回帰 線形回帰は勾配降下法を用いて計算するSGDRegressorクラスを利用してください。\n",
    "\n",
    "sklearn.linear_model.SGDRegressor — scikit-learn 0.21.3 documentation\n",
    "\n",
    "データセットは事前学習期間同様にHouse Pricesコンペティションのものを使います。\n",
    "\n",
    "House Prices: Advanced Regression Techniques\n",
    "\n",
    "train.csvをダウンロードし、目的変数としてSalePrice、説明変数として、GrLivAreaとYearBuiltを使います。\n",
    "＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿＿\n",
    "\n",
    "### 【問題3】 回帰問題を解くコードの作成 \n",
    "線形回帰でHouse Pricesデータセットを学習・推定するコードを作成してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\anai\\dive\\Dataset\\House Prices\\train.csv\")\n",
    "X = df.loc[:,[\"GrLivArea\", \"YearBuilt\"]]\n",
    "y = df.loc[:,[\"SalePrice\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anai\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\anai\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([144500, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 144500, 144500, 325000, 144500, 144500,\n",
       "       144500, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 144500, 144500, 144500, 144500, 325000,\n",
       "       144500, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 325000, 144500, 325000, 325000, 144500,\n",
       "       325000, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 325000, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       144500, 144500, 144500, 144500, 144500, 144500, 144500, 144500,\n",
       "       325000, 144500, 144500, 325000], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "X=np.array(X)\n",
    "y=np.array(y)\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y)\n",
    "LogiReg = SGDClassifier(loss=\"log\", random_state=0)\n",
    "LogiReg.fit(X_train, y_train)\n",
    "LogiReg.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
