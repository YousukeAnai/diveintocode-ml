{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0FJkChVM_EoS"
   },
   "source": [
    "## Model architecture tuning & score optimization\n",
    "\n",
    "\n",
    "Some ideas and code taken from ealier [kernel](https://www.kaggle.com/wrosinski/clean-workflow-in-keras) and last prepared notebook.\n",
    "\n",
    "Having dealt with data processing & engineering of channel features, next step of modeling is preparation and tuning of model architecture. Earlier notebooks provided a way to create images with three channels, which will facilitate usage of pretrained models.\n",
    "\n",
    "For segmentation tasks, a pretrained model can be used as encoder part of the final architecture. \n",
    "In order to use pretrained models, we will have to extract features from a few intermediate layers, which will then serve as a basis for layers coming afterwards and for skip connections between encoder and decoder part.\n",
    "\n",
    "ResNet50 is a good starting point, because it consists of 4 blocks, where each one of them can serve as feature extractor with first layer serving as the 5th extractor to achieve consistency with standard UNet architecture.\n",
    "\n",
    "モデルアーキテクチャの調整とスコアの最適化\n",
    "より古いカーネルと最後に準備されたノートブックから取られたいくつかのアイデアとコード。\n",
    "\n",
    "チャネル機能のデータ処理とエンジニアリングを扱った後、モデリングの次のステップは、モデルアーキテクチャの準備と調整です。以前のノートブックには、3つのチャネルを持つ画像を作成する方法が用意されていたため、事前学習済みのモデルを簡単に使用できます。\n",
    "\n",
    "セグメンテーションタスクの場合、事前トレーニング済みのモデルを最終アーキテクチャのエンコーダ部分として使用できます。事前学習済みのモデルを使用するには、いくつかの中間層から特徴を抽出する必要があります。この中間層は、その後に来る層の基礎として機能し、エンコーダーとデコーダー部分間の接続をスキップします。\n",
    "\n",
    "ResNet50は4つのブロックで構成されており、それぞれが機能抽出機能として機能し、最初のレイヤーが5番目の抽出機能として機能し、標準UNetアーキテクチャとの整合性を実現できるため、出発点として適しています。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 19822,
     "status": "ok",
     "timestamp": 1569393673542,
     "user": {
      "displayName": "やないようのすけ",
      "photoUrl": "",
      "userId": "08894667238863385509"
     },
     "user_tz": -540
    },
    "id": "bY92tlHr_PMu",
    "outputId": "9fea99d2-1164-492c-bfce-7eaf73f15f14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2932,
     "status": "ok",
     "timestamp": 1569393681960,
     "user": {
      "displayName": "やないようのすけ",
      "photoUrl": "",
      "userId": "08894667238863385509"
     },
     "user_tz": -540
    },
    "id": "jThgBvTU_EoU",
    "outputId": "487f120b-17ae-4325-fa44-5545685646ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.callbacks import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import *\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 586,
     "status": "ok",
     "timestamp": 1569393819552,
     "user": {
      "displayName": "やないようのすけ",
      "photoUrl": "",
      "userId": "08894667238863385509"
     },
     "user_tz": -540
    },
    "id": "pGPDqZIBJ-Hi",
    "outputId": "f0d6b44a-9872-4832-f93b-6de0de105d55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Sprint20_UNET_RESNET\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/content/drive/My Drive/Sprint20_UNET_RESNET')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3sXBWu9d_EoZ"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "# plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZWL8sVfo_Eoc"
   },
   "outputs": [],
   "source": [
    "def compute_coverage(df, masks):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    def cov_to_class(val):\n",
    "        for i in range(0, 11):\n",
    "            if val * 10 <= i:\n",
    "                return i\n",
    "\n",
    "    # Output percentage of area covered by class\n",
    "    df['coverage'] = np.mean(masks, axis=(1, 2))\n",
    "    # Coverage must be split into bins, otherwise stratified split will not be possible,\n",
    "    # because each coverage will occur only once.\n",
    "\n",
    "    df['coverage_class'] = df.coverage.map(\n",
    "        cov_to_class)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_depth_abs_channels(image_tensor):\n",
    "    image_tensor = image_tensor.astype(np.float32)\n",
    "    h, w, c = image_tensor.shape\n",
    "    for row, const in enumerate(np.linspace(0, 1, h)):\n",
    "        image_tensor[row, :, 1] = const\n",
    "    image_tensor[:, :, 2] = (\n",
    "        image_tensor[:, :, 0] * image_tensor[:, :, 1])\n",
    "\n",
    "    x_dx = np.diff(image_tensor[:, :, 0], axis=0)\n",
    "    x_dy = np.diff(image_tensor[:, :, 0], axis=1)\n",
    "    x_dx = cv2.copyMakeBorder(x_dx, 1, 0, 0, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    x_dy = cv2.copyMakeBorder(x_dy, 0, 0, 1, 0, cv2.BORDER_CONSTANT, 0)\n",
    "    image_tensor[:, :, 1] = np.abs(x_dx + x_dy)\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ESi3EYjK_Eoe"
   },
   "source": [
    "### Data loading & depth merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1705,
     "status": "ok",
     "timestamp": 1569393831503,
     "user": {
      "displayName": "やないようのすけ",
      "photoUrl": "",
      "userId": "08894667238863385509"
     },
     "user_tz": -540
    },
    "id": "RoRDPZlC_Eof",
    "outputId": "8fcc0f6b-9133-4664-d9ca-f60789243268",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "           id                                           rle_mask\n",
      "0  575d24d81d                                                NaN\n",
      "1  a266a2a9df                                          5051 5151\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...\n",
      "\n",
      "test:\n",
      "           id rle_mask\n",
      "0  155410d6fa      1 1\n",
      "1  78b32781d1      1 1\n",
      "2  63db2a476a      1 1\n",
      "3  17bfcdb967      1 1\n",
      "4  7ea0fd3c88      1 1\n",
      "\n",
      "           id                                           rle_mask    z\n",
      "0  575d24d81d                                                NaN  843\n",
      "1  a266a2a9df                                          5051 5151  794\n",
      "2  75efad62c1  9 93 109 94 210 94 310 95 411 95 511 96 612 96...  468\n",
      "3  34e51dba6a  48 54 149 54 251 53 353 52 455 51 557 50 659 4...  727\n",
      "4  4875705fb0  1111 1 1212 1 1313 1 1414 1 1514 2 1615 2 1716...  797\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('/content/drive/My Drive/Sprint20_UNET_RESNET/train.csv')\n",
    "test = pd.read_csv('/content/drive/My Drive/Sprint20_UNET_RESNET/sample_submission.csv')\n",
    "depth = pd.read_csv('/content/drive/My Drive/unet/depths.csv')\n",
    "\n",
    "train_src = '../input/train/'\n",
    "\n",
    "print('train:\\n{}'.format(train.head()))\n",
    "print('\\ntest:\\n{}'.format(test.head()))\n",
    "\n",
    "\n",
    "train = train.merge(depth, how='left', on='id')\n",
    "test = test.merge(depth, how='left', on='id')\n",
    "\n",
    "print('\\n{}'.format(train.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q9-TwyL4_Eoi"
   },
   "source": [
    "### Load images and masks, examine random sample:\n",
    "画像とマスクをロードし、ランダムサンプルを調べます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 186647,
     "status": "ok",
     "timestamp": 1569394021637,
     "user": {
      "displayName": "やないようのすけ",
      "photoUrl": "",
      "userId": "08894667238863385509"
     },
     "user_tz": -540
    },
    "id": "CSzlUsqC_Eoj",
    "outputId": "46b11979-77f4-4889-816f-fdc08b8fb50f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 101, 101) (300, 101, 101)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.asarray(\n",
    "    [cv2.imread('/content/drive/My Drive/unet/Train/images/{}.png'.format(x), 0) \n",
    "     for x in train.id.tolist()],dtype=np.uint8) / 255.\n",
    "#display(X_train)\n",
    "y_train = np.asarray(\n",
    "    [cv2.imread('/content/drive/My Drive/unet/Train/masks/{}.png'.format(x), 0) \n",
    "     for x in train.id.tolist()],dtype=np.uint8) / 255.\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1186,
     "status": "ok",
     "timestamp": 1569394026574,
     "user": {
      "displayName": "やないようのすけ",
      "photoUrl": "",
      "userId": "08894667238863385509"
     },
     "user_tz": -540
    },
    "id": "P0tMApLb_Eom",
    "outputId": "949dda0b-38d2-4693-f4fc-6ebae4fb513c",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3b758333c8>"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAFTCAYAAADCyzEvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nREQW+P8BpP8k11qInngAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_index = np.random.randint(0, X_train.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "ax[0].imshow(X_train[random_index], cmap='gray')\n",
    "ax[1].imshow(y_train[random_index], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vt-CfxeZ_Eop"
   },
   "source": [
    "### Compute salt coverage (this will serve as a basis for stratified split):\n",
    "ソルトカバレッジを計算します（これは、階層化された分割の基礎として機能します）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "geCpWcCv_Eoq"
   },
   "outputs": [],
   "source": [
    "train = compute_coverage(train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DrhfgXxl_Eot"
   },
   "source": [
    "### Prepare data for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1389,
     "status": "ok",
     "timestamp": 1569394033470,
     "user": {
      "displayName": "やないようのすけ",
      "photoUrl": "",
      "userId": "08894667238863385509"
     },
     "user_tz": -540
    },
    "id": "09YIR0UQ_Eot",
    "outputId": "563d3e08-e011-432b-f98c-dc2dc11a4dbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234, 224, 224, 3) (234, 224, 224, 1)\n",
      "(66, 224, 224, 3) (66, 224, 224, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=1337)\n",
    "\n",
    "# Add channel features\n",
    "X_train_ch = np.repeat(np.expand_dims(X_train, axis=-1), 3, -1)\n",
    "X_train_ch = np.asarray(list(map(lambda x: create_depth_abs_channels(x), X_train_ch)))\n",
    "\n",
    "# Resize to 224x224, default ResNet50 image size\n",
    "X_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), X_train_ch)))\n",
    "y_resized = np.asarray(list(map(lambda x: cv2.resize(x, (224, 224)), y_train)))\n",
    "\n",
    "\n",
    "for train_index, valid_index in kfold.split(train.id.values, train.coverage_class.values):\n",
    "    \n",
    "    X_tr, X_val = X_resized[train_index], X_resized[valid_index]\n",
    "    y_tr, y_val = y_resized[train_index], y_resized[valid_index]\n",
    "    \n",
    "    break\n",
    "    \n",
    "\n",
    "y_tr = np.expand_dims(y_tr, axis=-1)\n",
    "y_val = np.expand_dims(y_val, axis=-1)\n",
    "\n",
    "print(X_tr.shape, y_tr.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "\n",
    "\n",
    "del X_train_ch, y_resized\n",
    "del X_resized\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zDaHxjDC_Eow"
   },
   "source": [
    "### Loss functions & metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b2Past9t_Eox"
   },
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "# Dice & combined\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Lovash loss: https://github.com/bermanmaxim/LovaszSoftmax\n",
    "def lovasz_grad(gt_sorted):\n",
    "    \"\"\"\n",
    "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
    "    See Alg. 1 in paper\n",
    "    \"\"\"\n",
    "    gts = tf.reduce_sum(gt_sorted)\n",
    "    intersection = gts - tf.cumsum(gt_sorted)\n",
    "    union = gts + tf.cumsum(1. - gt_sorted)\n",
    "    jaccard = 1. - intersection / union\n",
    "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
    "    return jaccard\n",
    "\n",
    "\n",
    "# --------------------------- BINARY LOSSES ---------------------------\n",
    "\n",
    "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
    "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
    "      per_image: compute the loss per image instead of per batch\n",
    "      ignore: void class id\n",
    "    \"\"\"\n",
    "    if per_image:\n",
    "        def treat_image(log_lab):\n",
    "            log, lab = log_lab\n",
    "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
    "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
    "            return lovasz_hinge_flat(log, lab)\n",
    "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
    "        loss = tf.reduce_mean(losses)\n",
    "    else:\n",
    "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def lovasz_hinge_flat(logits, labels):\n",
    "    \"\"\"\n",
    "    Binary Lovasz hinge loss\n",
    "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
    "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
    "      ignore: label to ignore\n",
    "    \"\"\"\n",
    "\n",
    "    def compute_loss():\n",
    "        labelsf = tf.cast(labels, logits.dtype)\n",
    "        signs = 2. * labelsf - 1.\n",
    "        errors = 1. - logits * tf.stop_gradient(signs)\n",
    "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
    "        gt_sorted = tf.gather(labelsf, perm)\n",
    "        grad = lovasz_grad(gt_sorted)\n",
    "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
    "        return loss\n",
    "\n",
    "    # deal with the void prediction case (only void pixels)\n",
    "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
    "                   lambda: tf.reduce_sum(logits) * 0.,\n",
    "                   compute_loss,\n",
    "                   strict=True,\n",
    "                   name=\"loss\"\n",
    "                   )\n",
    "    return loss\n",
    "\n",
    "\n",
    "def flatten_binary_scores(scores, labels, ignore=None):\n",
    "    \"\"\"\n",
    "    Flattens predictions in the batch (binary case)\n",
    "    Remove labels equal to 'ignore'\n",
    "    \"\"\"\n",
    "    scores = tf.reshape(scores, (-1,))\n",
    "    labels = tf.reshape(labels, (-1,))\n",
    "    if ignore is None:\n",
    "        return scores, labels\n",
    "    valid = tf.not_equal(labels, ignore)\n",
    "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
    "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
    "    return vscores, vlabels\n",
    "\n",
    "\n",
    "def lovasz_loss(y_true, y_pred):\n",
    "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
    "    #logits = K.log(y_pred / (1. - y_pred))\n",
    "    logits = y_pred #Jiaxin\n",
    "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# IoU metric for observation during training\n",
    "# https://www.kaggle.com/cpmpml/fast-iou-metric-in-numpy-and-tensorflow\n",
    "def get_iou_vector(A, B):\n",
    "    # Numpy version    \n",
    "    batch_size = A.shape[0]\n",
    "    metric = 0.0\n",
    "    for batch in range(batch_size):\n",
    "        t, p = A[batch], B[batch]\n",
    "        true = np.sum(t)\n",
    "        pred = np.sum(p)\n",
    "        \n",
    "        # deal with empty mask first\n",
    "        if true == 0:\n",
    "            metric += (pred == 0)\n",
    "            continue\n",
    "        \n",
    "        # non empty mask case.  Union is never empty \n",
    "        # hence it is safe to divide by its number of pixels\n",
    "        intersection = np.sum(t * p)\n",
    "        union = true + pred - intersection\n",
    "        iou = intersection / union\n",
    "        \n",
    "        # iou metrric is a stepwise approximation of the real iou over 0.5\n",
    "        iou = np.floor(max(0, (iou - 0.45)*20)) / 10\n",
    "        \n",
    "        metric += iou\n",
    "        \n",
    "    # teake the average over all images in batch\n",
    "    metric /= batch_size\n",
    "    return metric\n",
    "\n",
    "\n",
    "def my_iou_metric(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
    "\n",
    "\n",
    "# For Lovash loss\n",
    "def my_iou_metric_2(label, pred):\n",
    "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5SG8jeHJ_Eo0"
   },
   "source": [
    "### Encoder features - ResNet50:\n",
    "\n",
    "In ResNet50, each block finishes with a pooling layer, so we can extract features from intermediate layers just before the pooling. This way, when first layer is added as additional extractor, we will have features extracted from 5 layers.\n",
    "Default input size will be assumed, which is (224, 224, 3).\n",
    "Layers will be as follows:\n",
    "\n",
    "- 'activation_1', shape: (None, 112, 112, 64)\n",
    "- 'activation_10', shape: (None, 56, 56, 256)\n",
    "- 'activation_22', shape: (None, 28, 28, 512)\n",
    "- 'activation_40', shape: (None, 14, 14, 1024)\n",
    "- 'activation_49', shape: (None, 7, 7, 2048)\n",
    "\n",
    "One thing to keep in mind is that every time a model will be created in the same TF session in the notebook, layer names will change, so above layer names correspond to first creation of the model. In order to reset session, call `K.clear_session()`.\n",
    "\n",
    "エンコーダー機能-ResNet50：\n",
    "ResNet50では、各ブロックはプーリングレイヤーで終了するため、プーリングの直前に中間レイヤーからフィーチャを抽出できます。このようにして、最初のレイヤーが追加の抽出機能として追加されると、5つのレイヤーからフィーチャが抽出されます。デフォルトの入力サイズ（（224、224、3））が想定されます。レイヤーは次のようになります。\n",
    "\n",
    "'activation_1'、形状：（なし、112、112、64）\n",
    "'activation_10'、形状：（なし、56、56、256）\n",
    "'activation_22'、形状：（なし、28、28、512）\n",
    "'activation_40'、形状：（なし、14、14、1024）\n",
    "'activation_49'、形状：（なし、7、7、2048）\n",
    "注意すべきことは、ノートブック内の同じTFセッションでモデルが作成されるたびにレイヤー名が変更されるため、上記のレイヤー名はモデルの最初の作成に対応するということです。セッションをリセットするには、を呼び出しますK.clear_session()。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "uX4ExzpH_Eo1"
   },
   "source": [
    "base_model = VGG16(input_shape=input_size, include_top=False)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eD50p2Y3_Eo2"
   },
   "source": [
    "### Decoder blocks:\n",
    "\n",
    "Features from ResNet50 will serve as a basis for encoder part of the segmentation model, now a decoder part is needed.\n",
    "For this part, we will have to create our own blocks. Let's create a very basic block and a second one, which structure will have a more complicated structure.\n",
    "\n",
    "デコーダーブロック：\n",
    "\n",
    "ResNet50の機能は、セグメンテーションモデルのエンコーダー部分の基盤として機能しますが、現在はデコーダー部分が必要です。\n",
    "この部分では、独自のブロックを作成する必要があります。 非常に基本的なブロックと2つ目のブロックを作成してみましょう。この構造はより複雑な構造になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "thUYRIlH_Eo2"
   },
   "outputs": [],
   "source": [
    "# Basic decoder block with Conv, BN and PReLU activation.\n",
    "def decoder_block_simple(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3)):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation'.format(block_name))(x_dec)\n",
    "\n",
    "    return x_dec\n",
    "\n",
    "# Decoder block with bottleneck architecture, where middle conv layer\n",
    "# is half the size of first and last, in order to compress representation.\n",
    "# This type of architecture is supposed to retain most useful information.\n",
    "#ボトルネックアーキテクチャを備えたデコーダブロック。中間コンバードレイヤー\n",
    "#は、表現を圧縮するために、最初と最後の半分のサイズです。\n",
    "#このタイプのアーキテクチャは、最も有用な情報を保持することになっています。\n",
    "def decoder_block_bottleneck(\n",
    "        layer_name, block_name,\n",
    "        num_filters=32,\n",
    "        conv_dim=(3, 3),\n",
    "        dropout_frac=0.2):\n",
    "\n",
    "    x_dec = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv1'.format(block_name))(layer_name)\n",
    "    x_dec = BatchNormalization(\n",
    "        name='{}_bn1'.format(block_name))(x_dec)\n",
    "    x_dec = PReLU(\n",
    "        name='{}_activation1'.format(block_name))(x_dec)\n",
    "    x_dec = Dropout(dropout_frac)(x_dec)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters // 2, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv2'.format(block_name))(x_dec)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation2'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Conv2D(\n",
    "        num_filters, conv_dim,\n",
    "        padding='same',\n",
    "        name='{}_conv3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = BatchNormalization(\n",
    "        name='{}_bn3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = PReLU(\n",
    "        name='{}_activation3'.format(block_name))(x_dec2)\n",
    "    x_dec2 = Dropout(dropout_frac)(x_dec2)\n",
    "\n",
    "    x_dec2 = Add()([x_dec, x_dec2])\n",
    "\n",
    "    return x_dec2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VaVtz67O_Eo5"
   },
   "source": [
    "### Model definition:\n",
    "\n",
    "Combine encoder and decoder blocks to create final segmentation model.\n",
    "\n",
    "エンコーダーブロックとデコーダーブロックを組み合わせて、最終的なセグメンテーションモデルを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mQKDW-br_Eo6"
   },
   "outputs": [],
   "source": [
    "# Model is parametrized in a way to enable easy change of decoder_block type,\n",
    "# as this is an argument that can be given a function, like decoder_block_simple.\n",
    "\n",
    "def unet_vgg16(input_size, decoder_block,\n",
    "                weights='imagenet',\n",
    "                loss_func='binary_crossentropy',\n",
    "                metrics_list=[my_iou_metric],\n",
    "                use_lovash=False):\n",
    "\n",
    "    # Base model - encoder\n",
    "    base_model = VGG16(\n",
    "        input_shape=input_size, \n",
    "        include_top=False,\n",
    "        weights=weights)\n",
    "    display(base_model.summary())\n",
    "    # Layers for feature extraction in the encoder part\n",
    "    encoder1 = base_model.get_layer('block2_conv2').output\n",
    "    encoder2 = base_model.get_layer('block3_conv3').output\n",
    "    encoder3 = base_model.get_layer('block4_conv3').output\n",
    "    encoder4 = base_model.get_layer('block5_conv3').output\n",
    "    encoder5 = base_model.get_layer('block5_pool').output\n",
    "\n",
    "    # Center block\n",
    "    center = decoder_block(\n",
    "        encoder5, 'center', num_filters=512)\n",
    "    concat5 = concatenate([center, encoder5], axis=-1)\n",
    "\n",
    "    # Decoder part.\n",
    "    # Every decoder block processed concatenated output from encoder and decoder part.\n",
    "    # This creates skip connections.\n",
    "    # Afterwards, decoder output is upsampled to dimensions equal to encoder output part.\n",
    "\n",
    "    decoder4 = decoder_block(\n",
    "        concat5, 'decoder4', num_filters=256)\n",
    "    concat4 = concatenate([UpSampling2D()(decoder4), encoder4], axis=-1)\n",
    "\n",
    "    decoder3 = decoder_block(\n",
    "        concat4, 'decoder3', num_filters=128)\n",
    "    concat3 = concatenate([UpSampling2D()(decoder3), encoder3], axis=-1)\n",
    "\n",
    "    decoder2 = decoder_block(\n",
    "        concat3, 'decoder2', num_filters=64)\n",
    "    concat2 = concatenate([UpSampling2D()(decoder2), encoder2], axis=-1)\n",
    "\n",
    "    decoder1 = decoder_block(\n",
    "        concat2, 'decoder1', num_filters=64)\n",
    "    concat1 = concatenate([UpSampling2D()(decoder1), encoder1], axis=-1)\n",
    "\n",
    "    # Final upsampling and decoder block for segmentation.\n",
    "    output = UpSampling2D()(concat1)\n",
    "    output = decoder_block(\n",
    "        output, 'decoder_output', num_filters=32)\n",
    "    output = Conv2D(\n",
    "        1, (1, 1), activation=None, name='prediction')(output)\n",
    "    if not use_lovash:\n",
    "        output = Activation('sigmoid')(output)\n",
    "        \n",
    "    model = Model(base_model.input, output)\n",
    "    model.compile(loss=loss_func, optimizer='adam', metrics=metrics_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pQU1kI-U_Eo9"
   },
   "source": [
    "### Inspect created model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6989,
     "status": "ok",
     "timestamp": 1569394135932,
     "user": {
      "displayName": "やないようのすけ",
      "photoUrl": "",
      "userId": "08894667238863385509"
     },
     "user_tz": -540
    },
    "id": "jji64-9V_Eo9",
    "outputId": "d0a97c5b-6ba7-42b3-9ded-c80063794a0e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 1s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From <ipython-input-15-910567864b2d>:153: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv (Conv2D)            (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_bn (BatchNormalization)  (None, 7, 7, 512)    2048        center_conv[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_activation (PReLU)       (None, 7, 7, 512)    25088       center_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           center_activation[0][0]          \n",
      "                                                                 block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv (Conv2D)          (None, 7, 7, 256)    2359552     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn (BatchNormalization (None, 7, 7, 256)    1024        decoder4_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation (PReLU)     (None, 7, 7, 256)    12544       decoder4_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           decoder4_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv (Conv2D)          (None, 14, 14, 128)  884864      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn (BatchNormalization (None, 14, 14, 128)  512         decoder3_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation (PReLU)     (None, 14, 14, 128)  25088       decoder3_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           decoder3_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv (Conv2D)          (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn (BatchNormalization (None, 28, 28, 64)   256         decoder2_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation (PReLU)     (None, 28, 28, 64)   50176       decoder2_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           decoder2_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv (Conv2D)          (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn (BatchNormalization (None, 56, 56, 64)   256         decoder1_conv[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation (PReLU)     (None, 56, 56, 64)   200704      decoder1_bn[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           decoder1_activation[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 192 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 192 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv (Conv2D)    (None, 224, 224, 32) 55328       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn (BatchNormali (None, 224, 224, 32) 128         decoder_output_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation (PReL (None, 224, 224, 32) 1605632     decoder_output_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          decoder_output_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 22,850,817\n",
      "Trainable params: 22,848,705\n",
      "Non-trainable params: 2,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_size = (224, 224, 3)\n",
    "\n",
    "\n",
    "K.clear_session()\n",
    "model = unet_vgg16(\n",
    "    input_size, decoder_block_simple, weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l1bdsth7_EpA"
   },
   "source": [
    "### Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 71960,
     "status": "ok",
     "timestamp": 1569394215322,
     "user": {
      "displayName": "やないようのすけ",
      "photoUrl": "",
      "userId": "08894667238863385509"
     },
     "user_tz": -540
    },
    "id": "tsU_yMen_EpB",
    "outputId": "de152cc2-d340-477e-fd00-0fffefdf71d5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 56, 56, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 28, 28, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 14, 14, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 512)    0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_conv1 (Conv2D)           (None, 7, 7, 512)    2359808     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "center_bn1 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation1 (PReLU)      (None, 7, 7, 512)    25088       center_bn1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 7, 7, 512)    0           center_activation1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv2 (Conv2D)           (None, 7, 7, 256)    1179904     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn2 (BatchNormalization) (None, 7, 7, 256)    1024        center_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation2 (PReLU)      (None, 7, 7, 256)    12544       center_bn2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 7, 7, 256)    0           center_activation2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "center_conv3 (Conv2D)           (None, 7, 7, 512)    1180160     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "center_bn3 (BatchNormalization) (None, 7, 7, 512)    2048        center_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "center_activation3 (PReLU)      (None, 7, 7, 512)    25088       center_bn3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 7, 7, 512)    0           center_activation3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 7, 7, 512)    0           dropout_1[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 7, 7, 1024)   0           add_1[0][0]                      \n",
      "                                                                 block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv1 (Conv2D)         (None, 7, 7, 256)    2359552     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn1 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation1 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv2 (Conv2D)         (None, 7, 7, 128)    295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn2 (BatchNormalizatio (None, 7, 7, 128)    512         decoder4_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation2 (PReLU)    (None, 7, 7, 128)    6272        decoder4_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 7, 7, 128)    0           decoder4_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_conv3 (Conv2D)         (None, 7, 7, 256)    295168      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_bn3 (BatchNormalizatio (None, 7, 7, 256)    1024        decoder4_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder4_activation3 (PReLU)    (None, 7, 7, 256)    12544       decoder4_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 7, 7, 256)    0           decoder4_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 7, 7, 256)    0           dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 14, 14, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 14, 14, 768)  0           up_sampling2d_1[0][0]            \n",
      "                                                                 block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv1 (Conv2D)         (None, 14, 14, 128)  884864      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn1 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation1 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv2 (Conv2D)         (None, 14, 14, 64)   73792       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn2 (BatchNormalizatio (None, 14, 14, 64)   256         decoder3_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation2 (PReLU)    (None, 14, 14, 64)   12544       decoder3_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 14, 14, 64)   0           decoder3_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_conv3 (Conv2D)         (None, 14, 14, 128)  73856       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_bn3 (BatchNormalizatio (None, 14, 14, 128)  512         decoder3_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder3_activation3 (PReLU)    (None, 14, 14, 128)  25088       decoder3_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 14, 14, 128)  0           decoder3_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 14, 14, 128)  0           dropout_7[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 28, 28, 128)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 28, 28, 640)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv1 (Conv2D)         (None, 28, 28, 64)   368704      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn1 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation1 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv2 (Conv2D)         (None, 28, 28, 32)   18464       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn2 (BatchNormalizatio (None, 28, 28, 32)   128         decoder2_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation2 (PReLU)    (None, 28, 28, 32)   25088       decoder2_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 28, 28, 32)   0           decoder2_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_conv3 (Conv2D)         (None, 28, 28, 64)   18496       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_bn3 (BatchNormalizatio (None, 28, 28, 64)   256         decoder2_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder2_activation3 (PReLU)    (None, 28, 28, 64)   50176       decoder2_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 28, 28, 64)   0           decoder2_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 64)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 56, 56, 64)   0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 56, 56, 320)  0           up_sampling2d_3[0][0]            \n",
      "                                                                 block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv1 (Conv2D)         (None, 56, 56, 64)   184384      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn1 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation1 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv2 (Conv2D)         (None, 56, 56, 32)   18464       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn2 (BatchNormalizatio (None, 56, 56, 32)   128         decoder1_conv2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation2 (PReLU)    (None, 56, 56, 32)   100352      decoder1_bn2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 56, 56, 32)   0           decoder1_activation2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_conv3 (Conv2D)         (None, 56, 56, 64)   18496       dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_bn3 (BatchNormalizatio (None, 56, 56, 64)   256         decoder1_conv3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder1_activation3 (PReLU)    (None, 56, 56, 64)   200704      decoder1_bn3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 56, 56, 64)   0           decoder1_activation3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 56, 56, 64)   0           dropout_13[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 112, 112, 64) 0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 112, 112, 192 0           up_sampling2d_4[0][0]            \n",
      "                                                                 block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 224, 224, 192 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv1 (Conv2D)   (None, 224, 224, 32) 55328       up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn1 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation1 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv2 (Conv2D)   (None, 224, 224, 16) 4624        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn2 (BatchNormal (None, 224, 224, 16) 64          decoder_output_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation2 (PRe (None, 224, 224, 16) 802816      decoder_output_bn2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 224, 224, 16) 0           decoder_output_activation2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_conv3 (Conv2D)   (None, 224, 224, 32) 4640        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_bn3 (BatchNormal (None, 224, 224, 32) 128         decoder_output_conv3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output_activation3 (PRe (None, 224, 224, 32) 1605632     decoder_output_bn3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 224, 224, 32) 0           decoder_output_activation3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 224, 224, 32) 0           dropout_16[0][0]                 \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "prediction (Conv2D)             (None, 224, 224, 1)  33          add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 224, 224, 1)  0           prediction[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 28,917,105\n",
      "Trainable params: 28,911,825\n",
      "Non-trainable params: 5,280\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 234 samples, validate on 66 samples\n",
      "Epoch 1/2\n",
      "234/234 [==============================] - 39s 167ms/step - loss: 1.2371 - my_iou_metric: 0.0526 - val_loss: 1.7734 - val_my_iou_metric: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_my_iou_metric improved from -inf to 0.00000, saving model to unet_vggnet16.h5\n",
      "Epoch 2/2\n",
      "234/234 [==============================] - 17s 72ms/step - loss: 1.0686 - my_iou_metric: 0.0889 - val_loss: 1.3516 - val_my_iou_metric: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_my_iou_metric did not improve from 0.00000\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "# Build model:\n",
    "# Here, you can experiment with various losses.\n",
    "# For dice and BCE (binary_crossentropy), my_iou_metric should be used,\n",
    "# whereas for lovash_loss my_iou_metric2 should be used, because range of values\n",
    "# for lovash loss is between -inf and +inf, not between 0 and 1, as for BCE and dice.\n",
    "# What is more, when lovash loss is used, last layer (sigmoid) should be deleted.\n",
    "# This is controlled by use_lovash parameter.\n",
    "#ここでは、さまざまな損失を試すことができます。\n",
    "#サイコロとBCE（binary_crossentropy）には、my_iou_metricを使用する必要があります。\n",
    "#一方、lovash_lossにはmy_iou_metric2を使用する必要があります。これは、値の範囲が\n",
    "#ロバシュ損失の＃は-infと+ infの間であり、BCEとサイコロのように0と1の間ではありません。\n",
    "#さらに、ロバッシュ損失を使用する場合、最後のレイヤー（シグモイド）を削除する必要があります。\n",
    "#これはuse_lovashパラメーターによって制御されます。\n",
    "model_depth = unet_vgg16(\n",
    "    input_size, decoder_block_bottleneck, weights='imagenet',\n",
    "    loss_func=bce_dice_loss, metrics_list=[my_iou_metric],\n",
    "    use_lovash=False)\n",
    "print(model_depth.summary())\n",
    "\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'unet_vggnet16.h5' ,monitor='val_my_iou_metric', mode='max',\n",
    "    save_best_only=True, save_weights_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_my_iou_metric',\n",
    "    mode='max',\n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    min_lr=0.0001, \n",
    "    verbose=1)\n",
    "\n",
    "\n",
    "epochs = 2  # 25\n",
    "batch_size = 16\n",
    "\n",
    "history = model_depth.fit(X_tr, y_tr,\n",
    "                    validation_data=[X_val, y_val], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[model_checkpoint,reduce_lr], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BWJhEtY4_EpE"
   },
   "source": [
    "### Validation set prediction and resizing to original size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "06Kscbdn_EpF"
   },
   "outputs": [],
   "source": [
    "val_preds = model_depth.predict(X_val, batch_size=16)\n",
    "\n",
    "y_val_pred = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), val_preds)))\n",
    "y_val_true = np.asarray(list(map(lambda x: cv2.resize(x, (101, 101)), y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcI0IGFT_EpI"
   },
   "source": [
    "### Threshold optimization: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qN_MBdbW_EpJ"
   },
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4217,
     "status": "ok",
     "timestamp": 1569394278780,
     "user": {
      "displayName": "やないようのすけ",
      "photoUrl": "",
      "userId": "08894667238863385509"
     },
     "user_tz": -540
    },
    "id": "F3IaXvqc_EpL",
    "outputId": "b3c7b955-771b-4d35-f252-7b9b0f61acb2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [00:03<00:00,  9.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# Threshold range, over which optimization is performed\n",
    "#最適化が実行されるしきい値範囲\n",
    "thresholds = np.arange(0.2, 0.9, 0.02)\n",
    "\n",
    "# For every threshold, set predictions to binary arrays, \n",
    "# where values above threshold are treated as 1 and the rest as 0.\n",
    "# Loop over thresholds and compute IoU for them based on IoU function above.\n",
    "#すべてのしきい値について、予測をバイナリ配列に設定し、\n",
    "#しきい値を超える値は1として処理され、残りは0として処理されます。\n",
    "#しきい値をループし、上記のIoU関数に基づいてIoUを計算します。\n",
    "ious = np.array(\n",
    "    [iou_metric_batch(y_val_true,\n",
    "                      np.int32(y_val_pred > threshold)) for threshold in tqdm(thresholds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 544,
     "status": "ok",
     "timestamp": 1569394281717,
     "user": {
      "displayName": "やないようのすけ",
      "photoUrl": "",
      "userId": "08894667238863385509"
     },
     "user_tz": -540
    },
    "id": "8Nbw6sAK_EpP",
    "outputId": "fcf00ef0-2eb1-4bb8-ac3e-8cfe7f1a4b90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best IoU: 0.3000 at threshold: 0.200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>iou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.061602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.204939</td>\n",
       "      <td>0.080297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.370000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.030303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.071212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       threshold        iou\n",
       "count  35.000000  35.000000\n",
       "mean    0.540000   0.061602\n",
       "std     0.204939   0.080297\n",
       "min     0.200000   0.000000\n",
       "25%     0.370000   0.000000\n",
       "50%     0.540000   0.030303\n",
       "75%     0.710000   0.071212\n",
       "max     0.880000   0.300000"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iou = pd.DataFrame(thresholds, columns=['threshold'])\n",
    "df_iou['iou'] = ious\n",
    "\n",
    "# Get index of best IoU\n",
    "best_index = df_iou['iou'].idxmax()\n",
    "print('Best IoU: {:.4f} at threshold: {:.3f}'.format(\n",
    "    df_iou.iou[best_index], df_iou.threshold[best_index]))\n",
    "\n",
    "# Describe IoU DF\n",
    "df_iou.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 897,
     "status": "ok",
     "timestamp": 1569394286495,
     "user": {
      "displayName": "やないようのすけ",
      "photoUrl": "",
      "userId": "08894667238863385509"
     },
     "user_tz": -540
    },
    "id": "HOWNlTXc_EpU",
    "outputId": "324bb186-f290-41d5-d2d5-51269606fe38",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3b21acca58>"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAswAAAIaCAYAAAA0thsoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xl83OV97v3rnhntkrWOFq/yIlmW\nF8DIZjG2CQZjAyXNRiBNQyBtTtrytOe0p23Snidtk/N0SZ/2tE+eNC1NIEvLljQ9TcNug7GNAVtm\nMbbkfZNsWbusfRnNff6QRITjZSyNdM9v5vN+vfSKNPrNzCUIcPmn733fxlorAAAAABfncx0AAAAA\niGUUZgAAAOAyKMwAAADAZVCYAQAAgMugMAMAAACXQWEGAAAALoPCDAAAAFwGhRkAAAC4DAozAAAA\ncBkUZgAAAOAyAq4DXKigoMCWlpa6jgEAAIA4t3fv3hZrbfBK18VcYS4tLVV1dbXrGAAAAIhzxphT\nkVzHSAYAAABwGRRmAAAA4DIozAAAAMBlxNwMMwAAAGLD0NCQ6uvr1d/f7zrKpKSmpmr27NlKSkqa\n0PMpzAAAALio+vp6ZWVlqbS0VMYY13EmxFqr1tZW1dfXa/78+RN6DUYyAAAAcFH9/f3Kz8/3bFmW\nJGOM8vPzJ3WXnMIMAACAS/JyWR4z2Z+BwgwAAICYdfPNN7uOQGEGAABA7Nq1a5frCBRmAAAAxK7M\nzExJI4v3fv/3f1/Lli3T8uXL9fTTT0uStm3bpnvuueeD6x955BF973vfi2oGdskAAADAFf3Zfx5Q\nzdnOqL5m5cwZ+pNfWhrRtT/5yU/07rvv6r333lNLS4tWrVqldevWRTXPpXCHGQAAADFv586deuCB\nB+T3+1VUVKT169drz5490/Le3GEGAADAFUV6J3i6BQIBhcPhD76eikNWuMMMAACAmLd27Vo9/fTT\nGh4eVnNzs7Zv367Vq1dr3rx5qqmp0cDAgDo6OrR169aovzd3mAEAABDzPvaxj+mNN97QNddcI2OM\nvvGNb6i4uFiSdN9992nZsmWaP3++rrvuuqi/t7HWRv1FJ6OqqspWV1e7jgEAAJDwamtrtWTJEtcx\nouJiP4sxZq+1tupKz41oJMMYs8kYc8gYc9QY8+WLfP9Lxpj3jTHvGmN2GmMqx33vK6PPO2SMuTOS\n9wMAAABixRULszHGL+lbkjZLqpT0wPhCPOoJa+1ya+21kr4h6W9Hn1sp6X5JSyVtkvQPo68HAAAA\neEIkd5hXSzpqrT1urR2U9JSkj46/wFo7flO+DEljcx4flfSUtXbAWntC0tHR17ska0c2pgYAAABi\nQSSFeZakunFf148+9iHGmN8yxhzTyB3m376a54534Ox5nWztjSAWAAAAplo83Mic7M8QtW3lrLXf\nstYulPSHkv7H1TzXGPNFY0y1MabaStp2qClasQAAADBBqampam1t9XRpttaqtbVVqampE36NSLaV\nOyNpzrivZ48+dilPSfr21TzXWvuopEclKWvOYvva4WY9tGZ+BNEAAAAwVWbPnq36+no1Nze7jjIp\nqampmj179oSfH0lh3iOpzBgzXyNl935Jnxl/gTGmzFp7ZPTLuyWNff5TSU8YY/5W0kxJZZJ2X+7N\nslICevN4q/qHhpWaxPpAAAAAV5KSkjR/Pjcxr1iYrbUhY8wjkl6U5Jf0mLX2gDHma5KqrbU/lfSI\nMeZ2SUOS2iU9OPrcA8aYZyTVSApJ+i1r7fDl3i8rNUn9Q2G9daJN68uDk/rhAAAAgMmKuYNLVl5f\nZbs3f12fvWGevvpLF+5eBwAAAERHVA8umU4+I924IF/bDrPwDwAAAO7FXGGWpPXlQR1v7lFdG9vL\nAQAAwK2YLcyS9Nphb6/IBAAAgPfFZGFeGMzQ7Nw0bTtEYQYAAIBbMVmYjTFaXx7UrmMtGgyFXccB\nAABAAovJwixJty4uVO/gsKpPtrmOAgAAgAQWs4X5poX5SvIb5pgBAADgVMwW5syUgFaV5lGYAQAA\n4FTMFmZpZLeMg+e61HC+z3UUAAAAJKjYLsyLR7aX285dZgAAADgS04V5cVGWimeksr0cAAAAnInp\nwjy2vdzOIy0aGmZ7OQAAAEy/mC7MknTr4qC6BkJ6t67DdRQAAAAkoJgvzDcvKpDfZ7TtUJPrKAAA\nAEhAMV+Ys9OStHJuDtvLAQAAwImYL8zSyKl/+890qqmr33UUAAAAJBhPFOb15SPby+043OI4CQAA\nABKNJwpzZckMFWSmMJYBAACAaeeJwuzzGa0rL9D2I80aDlvXcQAAAJBAPFGYpZGxjI7eIe2rZ3s5\nAAAATB/PFOZ1ZUEZI079AwAAwLTyTGHOzUjWNbPZXg4AAADTyzOFWRo59e+9+g619wy6jgIAAIAE\n4anCvL48KGul7Ue4ywwAAIDp4anCvGJ2jnLTkxjLAAAAwLTxVGH2+4zWlgW1/XCzwmwvBwAAgGng\nqcIsjYxltHQPqqah03UUAAAAJADPFeZ1o8dkM5YBAACA6eC5whzMStGyWTO07VCT6ygAAABIAJ4r\nzNLIWMbbpzt0vm/IdRQAAADEOU8W5lsXF2o4bPX60RbXUQAAABDnPFmYr5uTo6zUgF7jmGwAAABM\nMU8W5oDfp7VlBXrtcLOsZXs5AAAATB1PFmZpZI75XGe/DjV2uY4CAACAOObZwvzB9nKMZQAAAGAK\nebYwl2SnqaI4S9sozAAAAJhCni3M0shYRvWpNnUPhFxHAQAAQJzydmFeHNTQsNUbx1pdRwEAAECc\n8nRhrpqXp4xkP6f+AQAAYMp4ujAnB3y6eRHbywEAAGDqeLowSyNzzPXtfTrW3OM6CgAAAOJQXBRm\nSXrtMLtlAAAAIPo8X5jn5KVrYTCDwgwAAIAp4fnCLEnrywv15vFW9Q0Ou44CAACAOBMXhfnWxUEN\nhsJ68wTbywEAACC64qIwr56fp9QkH8dkAwAAIOriojCnJvl144J85pgBAAAQdXFRmCXp1vKgTrT0\n6FQr28sBAAAgeuKmMK9fXCiJ7eUAAAAQXXFTmOcXZGhefjpzzAAAAIiquCnM0sghJruOtap/iO3l\nAAAAEB1xV5j7hoZVfbLddRQAAADEibgqzDctzFey36fXDje5jgIAAIA4EVeFOT05oNXz87SNOWYA\nAABESVwVZmnk1L8jTd0609HnOgoAAADiQNwV5vXlQUlitwwAAABERdwV5kWFmZqZncocMwAAAKIi\n7gqzMUbrFxfq9aOtGhoOu44DAAAAj4u7wiyNjGV0D4S09xTbywEAAGBy4rIwr1mUr4DPcEw2AAAA\nJi0uC3NWapKun5fL9nIAAACYtLgszJK0fnFQtQ2dauzsdx0FAAAAHha3hfnW8kJJ0nbGMgAAADAJ\ncVuYl5RkqTArRdsozAAAAJiEuC3MxhitLw9q55EWDYet6zgAAADwqIgKszFmkzHmkDHmqDHmyxf5\n/u8aY2qMMfuMMVuNMfPGfW/YGPPu6MdPoxn+StaWB3W+b0j76jum820BAAAQR65YmI0xfknfkrRZ\nUqWkB4wxlRdc9o6kKmvtCkk/lvSNcd/rs9ZeO/pxb5RyR+SWRQUyRtpxpGU63xYAAABxJJI7zKsl\nHbXWHrfWDkp6StJHx19grX3VWts7+uWbkmZHN+bE5GUka/msbO04whwzAAAAJiaSwjxLUt24r+tH\nH7uUL0h6ftzXqcaYamPMm8aYX55AxklZW1agt093qKt/aLrfGgAAAHEgqov+jDGflVQl6a/HPTzP\nWlsl6TOS/s4Ys/Aiz/viaKmubm6O7t3gtWVBDYet3jjWGtXXBQAAQGKIpDCfkTRn3NezRx/7EGPM\n7ZL+WNK91tqBscettWdG//e4pG2SrrvwudbaR621VdbaqmAweFU/wJWsnJur9GQ/c8wAAACYkEgK\n8x5JZcaY+caYZEn3S/rQbhfGmOsk/ZNGynLTuMdzjTEpo58XSFojqSZa4SORHPDppgX5zDEDAABg\nQq5YmK21IUmPSHpRUq2kZ6y1B4wxXzPGjO168deSMiX96ILt45ZIqjbGvCfpVUl/aa2d1sIsjcwx\nn2zt1enW3itfDAAAAIwTiOQia+1zkp674LGvjvv89ks8b5ek5ZMJGA1ry0fGPLYfadZn8+dd4WoA\nAADg5+L2pL/xFhRkaFZOGmMZAAAAuGoJUZiNMVpXXqBdR1sVGg67jgMAAAAPSYjCLI1sL9c1ENJ7\nHJMNAACAq5AwhfnmhfnyGWn7YbaXAwAAQOQSpjDnpCdrxewc5pgBAABwVRKmMEvSurICvVvXofO9\nHJMNAACAyCRUYV5bHlTYSruOMZYBAACAyCRUYb52To6yUgLazjHZAAAAiFBCFeYkv083LczX9sPN\nsta6jgMAAAAPSKjCLI2MZZzp6NNJjskGAABABBKuMK8rK5AkdssAAABARBKuMM/Lz9DcvHT2YwYA\nAEBEEq4wS9LasgK9caxFgyGOyQYAAMDlJWhhDqpncFjvnG53HQUAAAAxLiEL882L8uX3Ge1gezkA\nAABcQUIW5hmpSbpuDsdkAwAA4MoSsjBLI2MZ+86cV3vPoOsoAAAAiGGJW5jLC2St9DrHZAMAAOAy\nErYwr5iVrRmpAe1gezkAAABcRsIW5oDfpzWLCrT9CMdkAwAA4NIStjBLI3PMDef7day523UUAAAA\nxKgEL8wjx2Rz6h8AAAAuJaEL85y8dC0oyGB7OQAAAFxSQhdmaeQu85vH2zQQGnYdBQAAADGIwlwW\nVN/QsPae4phsAAAA/KKEL8w3LsxXgGOyAQAAcAkJX5gzUwJaOS9X2w8zxwwAAIBflPCFWZLWlRXo\nwNlOtXQPuI4CAACAGENhlrSuPChJev0oYxkAAAD4MAqzpKUzs5WbnsR+zAAAAPgFFGZJfp/RmkUF\n2sEx2QAAALgAhXnUurKgmroGdLiRY7IBAADwcxTmUbeMHpPNqX8AAAAYj8I8amZOmhYVZuo1tpcD\nAADAOBTmcdaWFWj3iTb1D3FMNgAAAEZQmMdZVx7UQCisPSfbXEcBAABAjKAwj3PD/Dwl+30ckw0A\nAIAPUJjHSU8OqKqUY7IBAADwcxTmC6wtC+rguS41dfa7jgIAAIAYQGG+wNrR7eV2ckw2AAAARGH+\nBZUlM5SfkcxYBgAAACRRmH+Bz2d0S1mBdh5tUTjMMdkAAACJjsJ8EevKgmrpHlTtuU7XUQAAAOAY\nhfki1n5wTDZzzAAAAImOwnwRhTNSVVGcpR1HmGMGAABIdBTmS1hbVqA9J9rVN8gx2QAAAImMwnwJ\na8uCGhwO680Tra6jAAAAwCEK8yWsnp+n5IBPOw4zxwwAAJDIKMyXkJrk1w3z85hjBgAASHAU5stY\nVxbUkaZuNZzvcx0FAAAAjlCYL2NtOdvLAQAAJDoK82UsLspSMCuFwgwAAJDAKMyXYYzR2rIC7TzS\nzDHZAAAACYrCfAXryoJq7x3S/rPnXUcBAACAAxTmK1iziDlmAACAeHOsuTviaynMVxDMSlFlyQxt\nP8z2cgAAAPHiT396IOJrKcwRWFce1Nun29U9EHIdBQAAAJN0urX3qqYHKMwRWFdWoKFhq7eOc0w2\nAACA1z2157R8JvLrKcwRuL40V6lJPuaYAQAAPG5oOKxnqut1W0VRxM+hMEcgJeDXjQvytZ1jsgEA\nADxta22jWroH9Jkb5kT8HApzhNaWBXW8uUf17b2uowAAAGCCnthdp5LsVK0vL4z4ORTmCK0rY3s5\nAAAAL6tr69WOI8369Ko58l/FEDOFOUKLCjM1MztVW2ubXEcBAADABDy9p05G0qdXRT6OIVGYI2aM\n0calxdp+pJnt5QAAADxmZLFfnW6rKFRJdtpVPZfCfBU2LyvWYCisVw9ylxkAAMBLXjnYpKauAT2w\neu5VPzeiwmyM2WSMOWSMOWqM+fJFvv+7xpgaY8w+Y8xWY8y8cd970BhzZPTjwatOGEOqSvNUkJms\nF/afcx0FAAAAV+HJ3adHF/sFr/q5VyzMxhi/pG9J2iypUtIDxpjKCy57R1KVtXaFpB9L+sboc/Mk\n/YmkGyStlvQnxpjcq04ZI/y+kbGMVw81qX9o2HUcAAAARKC+vVevHW7WfVVzFPBf/YBFJM9YLemo\ntfa4tXZQ0lOSPjr+Amvtq9basf3W3pQ0e/TzOyW9bK1ts9a2S3pZ0qarThlDNi8rVu/gsF47zJ7M\nAAAAXjC22O++q1zsNyaSwjxLUt24r+tHH7uUL0h6foLPjXk3LshXTnoSYxkAAAAeEBoO6+k9dbp1\ncaFm5VzdYr8xgWgGMsZ8VlKVpPVX+bwvSvqiJM2de/WD2NMpye/THUuK9MKBcxoMhZUcYN0kAABA\nrJrMYr8xkbS9M5LG37+ePfrYhxhjbpf0x5LutdYOXM1zrbWPWmurrLVVweDVD2JPt83Li9XVH9Lr\nxzjEBAAAIJY9ufu0imak6COLJ94xIynMeySVGWPmG2OSJd0v6afjLzDGXCfpnzRSlsfvufaipI3G\nmNzRxX4bRx/ztDWLCpSVEtDz7ze4jgIAAIBLONPRp22Hm/XpCS72G3PFkQxrbcgY84hGiq5f0mPW\n2gPGmK9JqrbW/lTSX0vKlPQjY4wknbbW3mutbTPGfF0jpVuSvmatbZtw2hiREvDrtiWFermmUaHh\n8KT+BgAAAGBqPL1nZCndRBf7jYlohtla+5yk5y547KvjPr/9Ms99TNJjEw0YqzYvK9Z/vHtWb51o\n05pFBa7jAAAAYJzQcFjP7KnT+vKgZuemT+q1uDU6QevLC5WW5Nfz+xnLAAAAiDXbDjXrXGf/pBb7\njaEwT1Basl+3Lg7qxQONCoet6zgAAAAY58ndp1WYlaLbKgon/VoU5knYtKxYzV0D2nu63XUUAAAA\njDrb0adXDzXpvqo5SorCWjMK8yTcVlGo5IBPz7/PISYAAACx4pnqOllJn57kYr8xFOZJyEpN0rqy\nAr2wv0HWMpYBAADg2nDY6uk9dVpbFtScvMkt9htDYZ6kTctKdPZ8v96rP+86CgAAQMJ77XCTGs73\n6zOro3N3WaIwT9odS4oU8Bl2ywAAAIgBT7xVp4LMFG1YUhS116QwT1J2epJuWpivF/afYywDAADA\noXPn+/XKwUbdVzU7Kov9xlCYo2DzshKdau1VbUOX6ygAAAAJ65nqOoWtdP+qye+9PB6FOQo2Li2S\nz0gvMJYBAADgxM8X+xVobn50FvuNoTBHQUFmilaV5un5/WwvBwAA4ML2I80609EXlZP9LkRhjpK7\nlpfoSFO3jjZ1u44CAACQcJ5867QKMpN1exQX+42hMEfJnUuLJTGWAQAAMN0aO/u19WCTPnn9HCUH\nol9vKcxRUpydqpVzc/Qcp/4BAABMqx9V12k4bHV/lE72uxCFOYo2LytRTUOnTrf2uo4CAACQEMJh\nqyd312nNonyVFmRMyXtQmKNo07KRsQwOMQEAAJgeO462TNlivzEU5iiak5euZbNmsFsGAADANHny\nrdPKz0jWxsriKXsPCnOUbV5WonfrOtRwvs91FAAAgLjW1NmvLbWN+uT1s6dksd8YCnOUjY1lvMBd\nZgAAgCn1o731CoWtPj1Fi/3GUJijbGEwU+VFmYxlAAAATKFw2OqpPad104J8LQhmTul7UZinwOZl\nJdpzsk3NXQOuowAAAMSl14+1qK6tTw/cMHWL/cZQmKfA5uXFslZ68QB3mQEAAKbCk7tPKy8jWXcu\njf7JfheiME+BxUVZml+QwRwzAADAFGjuGtBLB0YW+6UE/FP+fhTmKWCM0aZlxXrjeKvaewZdxwEA\nAIgrPx5d7DdVJ/tdiMI8RTYvK9Zw2Orl2kbXUQAAAOLG2GK/GxfkTflivzEU5imyfFa2ZuWkMZYB\nAAAQRW8cb9Wp1t4pPdnvQhTmKTI2lrHzSIu6+odcxwEAAIgLT+w+rdz0JN25dOpO9rsQhXkKbV5W\nrMHhsF452OQ6CgAAgOe1dA/opQPn9ImVs5WaNPWL/cZQmKfQyrm5KsxK0XPvN7iOAgAA4Hk/3luv\noWGr+6dxHEOiME8pn29kLOO1w83qHQy5jgMAAOBZ4bDVU7tPa/X8PC0qnJ7FfmMozFNs07Ji9Q+F\nte1Qs+soAAAAnvXmiVadbO3VZ6b57rJEYZ5yq0vzlJeRrOfZLQMAAGDC3jzeJp+RNk7DyX4XojBP\nsYDfp42VRXqltlH9Q8Ou4wAAAHhSzdlOLQhmKj05MO3vTWGeBpuWFatncFg7j7S4jgIAAOBJtQ2d\nqiyZ4eS9KczT4OaFBcpKDTCWAQAAMAEdvYM609GnypkU5riVHPDpjiVFernmnAZDYddxAAAAPKW2\noUuSuMMc7zYvL1Fnf0hvHG91HQUAAMBTaho6JUlLKMzxbW1ZgTKS/XphP4eYAAAAXI2as50KZqUo\nmJXi5P0pzNMkNcmvj1QU6qUDjRoOW9dxAAAAPKPG4YI/icI8rTYvK1Frz6B2n2hzHQUAAMATBkNh\nHW3qcrbgT6IwT6tbFweVEvAxlgEAABCho03dGhq2zuaXJQrztMpICWh9eVAvHDinMGMZAAAAVzS2\n4I+RjASyeXmxGjsH9E5dh+soAAAAMa/mbKdSk3yaX5DhLAOFeZrdVlGkJL9hLAMAACACtQ2dqiie\nIb/POMtAYZ5m2WlJWrOoQM+9f07WMpYBAABwKdZa1TR0Op1flijMTty1rERnOvq0/0yn6ygAAAAx\n6+z5fp3vG3K6Q4ZEYXbijsoi+X1GzzOWAQAAcEk1Z90v+JMozE7kZiTrxgV5emE/YxkAAACXUtvQ\nKWOkiuIspzkozI5sWlai4y09OtzY7ToKAABATKo526nS/AxlpASc5qAwO3Ln0iL5jPTs+4xlAAAA\nXIzrI7HHUJgdKcxK1Q3z8/WzfWcZywAAALhAV/+QTrf1Ol/wJ1GYnbp7RYmON/fo4Lku11EAAABi\nylg/4g5zgtu0rHhkLGMfYxkAAADjje2Q4XoPZonC7FRBZopuXljAWAYAAMAFas52Ki8jWUUzUlxH\noTC7dveKEp1s7dWBsxxiAgAAMGZswZ8x7o7EHkNhduzOpcXy+wy7ZQAAAIwKDYd1qLErJhb8SRRm\n5/IykrVmEWMZAAAAY4639GgwFNaSErcHloyhMMeAe5aXqK6tT++fOe86CgAAgHM/PxI723GSERTm\nGLBxaZECPsNuGQAAABqZX04O+LQgmOE6iiQKc0zISU/W2rIC/WxfA2MZAAAg4dU2dGpxUZaS/LFR\nVWMjBXT3ipk609Gnd+s6XEcBAABwxlqrmrOdMTO/LFGYY8YdlUVK8jOWAQAAEltT14BaewZj4oS/\nMRTmGJGdlqR1ZUE9+36DwmHGMgAAQGL6YMHfzNhY8CdRmGPKPdeUqOF8v96pa3cdBQAAwImahpHC\nXMFIBi7m9iVFSg749DPGMgAAQIKqaejUnLw0zUhNch3lAxEVZmPMJmPMIWPMUWPMly/y/XXGmLeN\nMSFjzCcv+N6wMebd0Y+fRit4PMpKTdL68qCeYywDAAAkqNqznTE1vyxFUJiNMX5J35K0WVKlpAeM\nMZUXXHZa0uclPXGRl+iz1l47+nHvJPPGvXtWlKixc0DVpxjLAAAAiaV3MKQTrT0xc2DJmEjuMK+W\ndNRae9xaOyjpKUkfHX+BtfaktXafpPAUZEwoG5YUKSXg07P7zrqOAgAAMK0OnuuStVLlTI/dYZY0\nS1LduK/rRx+LVKoxptoY86Yx5pevKl0CykwJ6COLC/Xc/nMaZiwDAAAkkLEdMmJpD2Zpehb9zbPW\nVkn6jKS/M8YsvPACY8wXR0t1dXNz8zREim33XFOi5q4B7T7R5joKAADAtKlp6NSM1IBm5aS5jvIh\nkRTmM5LmjPt69uhjEbHWnhn93+OStkm67iLXPGqtrbLWVgWDwUhfOm7dVlGo1CSfnn2fsQwAAJA4\nas52qnLmDBljXEf5kEgK8x5JZcaY+caYZEn3S4potwtjTK4xJmX08wJJayTVTDRsokhPDmhDRZFe\n2H9OoWHGwgEAQPwbDlsdOtcVcwv+pAgKs7U2JOkRSS9KqpX0jLX2gDHma8aYeyXJGLPKGFMv6VOS\n/skYc2D06UskVRtj3pP0qqS/tNZSmCNwz4oStXQP6i3GMgAAQAI42dqjvqHhmJtflqRAJBdZa5+T\n9NwFj3113Od7NDKqceHzdklaPsmMCenWxYVKT/brZ/satGZRges4AAAAU+rnR2LH1g4ZEif9xay0\nZL82LCnSC/sbGMsAAABxr6ahU0l+o7LC2LvDTGGOYfesKFF775B2HWt1HQUAAGBK1TZ0alFhlpID\nsVdPYy8RPrC+PKiMZL+e3dfgOgoAAMCUqjnbGZPzyxKFOaalJvl1R2WRXjhwTkOMZQAAgDjV3DWg\npq4BVZbE3vyyRGGOefesmKnzfUPaebTFdRQAAIApUdsQuwv+JApzzFtbXqCslABjGQAAIG59UJi5\nw4yJSAn4dcfSIr144JwGQ4xlAACA+FPT0KmZ2anKSU92HeWiKMwe8EsrZqqrP6QdR5pdRwEAAIi6\nsSOxYxWF2QPWLCrQjFTGMgAAQPzpHxrWsebumB3HkCjMnpAc8OnOpcV6uaZR/UPDruMAAABEzeHG\nLoVt7C74kyjMnnHPNTPVNRDS9sOMZQAAgPgxdiT2Eu4wY7JuXpivnPQkPfs+YxkAACB+1DR0KjMl\noDm56a6jXBKF2SOS/D5tWlqsLYxlAACAOFLbMHLCn89nXEe5JAqzh9y9okQ9g8PadqjJdRQAAIBJ\nC4etahu6YnrBn0Rh9pSbFuQrLyNZP2O3DAAAEAfq2nvVPRCK6fllicLsKQG/T5uWFWtrbZP6BhnL\nAAAA3ja24C+Wd8iQKMyec8/yEvUNDeuVg4xlAAAAb6tt6JTfZ1RelOU6ymVRmD3mhgX5KshM1rPv\nn3UdBQAAYFJqGjq1MJih1CS/6yiXRWH2GL/PaPOyEr1ysEk9AyHXcQAAACas5mxnzM8vSxRmT7p7\nRYn6h8LaylgGAADwqI7eQZ093x/zO2RIFGZPWlWap8KsFD27j7EMAADgTTUN3ljwJ1GYPcnvM7pr\neYlePdSsbsYyAACAB3nhSOw7Vgs1AAAgAElEQVQxFGaPuntFiQZDYW2tbXQdBQAA4KrVNHSqMCtF\nBZkprqNcEYXZo66fm6viGan6z/c4xAQAAHhPzdlOT4xjSBRmz/KNjmVsP9yszv4h13EAAAAiNhgK\n61hztycW/EkUZk+7e0WJBofD2lLDWAYAAPCOI01dGhq23GHG1Fs5N0ezctL0s32MZQAAAO/w0oI/\nicLsacYY3bW8WDuONOt8L2MZAADAG2oaOpWW5FdpfobrKBGhMHvc3StmamjY6qWac66jAAAARKS2\noVMVJVny+4zrKBGhMHvcNbOzNTuXsQwAAOAN1tqRHTI8Mo4hUZg9zxiju1eU6PWjLWrvGXQdBwAA\n4LLOdPSpsz/kmfllicIcF+5ZPlOhMGMZAAAg9o0t+PPKDhkShTkuLJs1Q/Py0xnLAAAAMa+2oUvG\nSBXFWa6jRIzCHAdGdsso0a5jrYxlAACAmFbTcF7zCzKUnhxwHSViFOY4sWlpsYbDVq8cbHIdBQAA\n4JJqGjo9Nb8sUZjjxvJZ2SqekcocMwAAiFmd/UOqa+vz1A4ZEoU5bvh8RndUFum1w83qGxx2HQcA\nAOAXHGzokuStBX8ShTmubFxapP6hsHYebXEdBQAA4BfUnD0vSVrKHWa4csP8fGWlBvTSAcYyAABA\n7Klp6FR+RrKCWSmuo1wVCnMcSQ74tKGiUFtqGxUaDruOAwAA8CE1DZ2qnDlDxnjjSOwxFOY4s3Fp\nsdp7h1R9qt11FAAAgA8MDYd1uLHbcwv+JApz3FlXHlRywKeXDjS6jgIAAPCB4809GgyFPbfgT6Iw\nx53MlIBuWVSgl2rOyVrrOg4AAICkkQNLJHluD2aJwhyXNlYWqb69T7WjW7cAAAC4VnO2U8kBnxYU\nZLiOctUozHFow5IiGSMOMQEAADGjtqFLFcVZCvi9Vz+9lxhXFMxK0fVzc5ljBgAAMcFaO7JDhgfH\nMSQKc9y6c2mxaho6VdfW6zoKAABIcI2dA2rrGfTk/LJEYY5bd1QWSZJequEuMwAAcGtswZ8Xd8iQ\nKMxxq7QgQ4uLsjj1DwAAODe2EUFFcZbjJBNDYY5jG5cWac/JNrX1DLqOAgAAEljN2U7Ny09XVmqS\n6ygTQmGOYxsrixW20tZaxjIAAIA7NQ2dWlLszXEMicIc15bNmqGZ2anMMQMAAGd6BkI62drj2fll\nicIc14wx2ri0WNsPN6t3MOQ6DgAASEAHz3XJWnl2SzmJwhz3NlYWaSAU1vbDLa6jAACABFTT0CnJ\nuztkSBTmuLdqfp6y05I49Q8AADhRc7ZT2WlJKslOdR1lwijMcS7J79OGikJtrW1SaDjsOg4AAEgw\nYyf8GWNcR5kwCnMC2Li0SOf7hrT7ZJvrKAAAIIEMh60Onev09DiGRGFOCOvKg0oJ+PTSAXbLAAAA\n0+dES4/6h8KeXvAnUZgTQnpyQGvLCvRyTaOsta7jAACABDG24G8JhRlesHFpsc509OnA2U7XUQAA\nQIKoOdupJL/RosJM11EmhcKcIDZUFMpnpJcOsFsGAACYHrUNnSorzFJywNuV09vpEbH8zBRVleZx\n6h8AAJg2NQ3eX/AnUZgTysbKIh0816VTrT2uowAAgDh3tqNPzV0Dnl/wJ1GYE8rGymJJ0svcZQYA\nAFPslYNNkqR15QWOk0wehTmBzM1PV0VxFtvLAQCAKbe1tlHz8tO1MOjtBX9ShIXZGLPJGHPIGHPU\nGPPli3x/nTHmbWNMyBjzyQu+96Ax5sjox4PRCo6JuXNpsapPtamle8B1FAAAEKd6B0N6/VirNlQU\nefqEvzFXLMzGGL+kb0naLKlS0gPGmMoLLjst6fOSnrjguXmS/kTSDZJWS/oTY0zu5GNjojYuLVLY\njvypDwAAYCrsONKiwVBYt1cWuo4SFZHcYV4t6ai19ri1dlDSU5I+Ov4Ca+1Ja+0+SeELnnunpJet\ntW3W2nZJL0vaFIXcmKDKkhmalZPGWAYAAJgyW2sblZUa0KrSPNdRoiKSwjxLUt24r+tHH4vEZJ6L\nKWCM0calRdpxtEU9AyHXcQAAQJwJh61eOdikWxcXKskfH8vlYuKnMMZ80RhTbYypbm5udh0n7m2s\nLNZgKKzth/lrDQAAouvd+g61dA/q9iXxMY4hRVaYz0iaM+7r2aOPRSKi51prH7XWVllrq4LBYIQv\njYlaVZqrnPQkDjEBAABRt7W2UX6f0a3liVWY90gqM8bMN8YkS7pf0k8jfP0XJW00xuSOLvbbOPoY\nHAr4fdpQUaSttY0aGr5w7BwAAGDittQ0aXVpnrLTk1xHiZorFmZrbUjSIxopurWSnrHWHjDGfM0Y\nc68kGWNWGWPqJX1K0j8ZYw6MPrdN0tc1Urr3SPra6GNw7M6lRersD+mt4/ztAAAA0VHX1qtDjV3a\nEEfjGJIUiOQia+1zkp674LGvjvt8j0bGLS723MckPTaJjJgCa8uCSk3y6aWac7qlzPsn8AAAAPe2\njG5be/uSIsdJoismFv1h+qUl+7WuLKiXDjTKWus6DgAAiANba5u0qDBTpQUZrqNEFYU5gW1cWqxz\nnf16/8x511EAAIDHdfYP6c3jrXE3jiFRmBPahopC+Yw4xAQAAEza9sPNCoWt7oizcQyJwpzQcjOS\ntXp+nl6qOec6CgAA8LittU3Ky0jWdXNzXUeJOgpzgrtzabEON3brREuP6ygAAMCjQsPh0dP9gvL7\njOs4UUdhTnB3VI782uSlA9xlBgAAE7P3VLvO9w3F5TiGRGFOeLNz07V05gxO/QMAABO2pbZRyX6f\n1pbH54nNFGZoY2Wx3j7drqauftdRAACAB22tbdINC/KUmRLRER+eQ2GGNi4tkrUj/2cHAAC4Gsea\nu3W8peeDMc94RGGGKoqzNCcvjTlmAABw1baOnu53W0X87b88hsIMGWN0Z2WxXj/aqu6BkOs4AADA\nQ7bUNmlJyQzNzk13HWXKUJghaeTUv8HhsLYdYiwDAABEpr1nUNUn23R7HJ7uNx6FGZKk6+flKi8j\nmVP/AABAxLYdblLYShvidDu5MRRmSJL8PqPblxTq1YNNGgyFXccBAAAesKW2ScGsFK2Yle06ypSi\nMOMDGyuL1TUQ0pvHW11HAQAAMW4wFNZrh5q1oaJQvjg83W88CjM+cEtZgdKS/Hqpht0yAADA5e0+\n0abugZBuj/NxDInCjHFSk/xaXx7UyzWNCoet6zgAACCGbaltVErApzWLClxHmXIUZnzIncuK1Ng5\noH1nzruOAgAAYpS1VltqG3XLogKlJftdx5lyFGZ8yG2Li+T3Gb3IISYAAOASDjd2q769T7fH8el+\n41GY8SHZ6Um6cUEep/4BAIBL2jJ6ut+GOD7dbzwKM37BxspiHWvu0dGmbtdRAABADNpS26gVs7NV\nOCPVdZRpQWHGL7hj9Ncr7JYBAAAu1Nw1oHfrOhJid4wxFGb8gpk5aVo5N0f/+uZp9Q8Nu44DAABi\nyKsHm2SttCHOj8Mej8KMi/q9jYt1pqNPP3zjlOsoAAAghmypbdTM7FRVlsxwHWXaUJhxUWsWFWh9\neVDffOWIOnoHXccBAAAxoH9oWDuOtGjDkiIZE9+n+41HYcYlfeWuCnUNhPStV4+6jgIAAGLAG8da\n1Tc0nFDjGBKFGZdRUTxDn1w5W9/fdUp1bb2u4wAAAMderm1URrJfNy3Mdx1lWlGYcVm/u7FcPp/0\n/750yHUUAADgkLVWr9Q2aW1ZUCmB+D/dbzwKMy6rJDtNX7hlvv7j3bN6v57jsgEASFQHznbqXGd/\nwpzuNx6FGVf0X9YvVF5Gsv78uVpZa13HAQAADrxc0yhjpI8sDrqOMu0ozLiiGalJ+u3bFumN463a\ndqjZdRwAAODA1oONWjk3V/mZKa6jTDsKMyLymRvmqTQ/XX/xfK2Gw9xlBgAgkTSc79P+M50Jdbrf\neBRmRCQ54NMfbKrQ4cZu/dveetdxAADANNpa2yRJuj3BtpMbQ2FGxDYvK9a1c3L0Ny8fUu9gyHUc\nAAAwTbbWNmpefroWFWa6juIEhRkRM8boj+9eosbOAT2284TrOAAAYBr0Dob0+rFWbahIrNP9xqMw\n46qsKs3Txsoi/eNrx9XSPeA6DgAAmGI7jrRoMBRO2HEMicKMCfiDTRXqGxrWN7cecR0FAABMsS01\njcpKDWjV/DzXUZyhMOOqLSrM1P2r5uhf3zqt483druMAAIApEg5bvXqoSbcuLlSSP3FrY+L+5JiU\n/3p7uZIDPv31ixyZDQBAvHq3vkMt3YMJPY4hUZgxQcGsFP2XdQv1/P5z2nuq3XUcAAAwBbbUNMrv\nM7q1nMIMTMivrZ2vYFYKR2YDABCnttY2aVVprrLTk1xHcYrCjAnLSAnov91err2n2vXigUbXcQAA\nQBTVtfXqUGNXwp7uNx6FGZNyX9VsLSrM1DdeOKih4bDrOAAAIEq21I7cDKMwU5gxSQG/T1/eVKHj\nLT16avdp13EAAECUbK1t0sJghkoLMlxHcY7CjEnbsKRQq+fn6e+2HFH3AEdmAwDgdZ39Q3rzeKtu\nr+TuskRhRhQYY/RHdy1Ra8+gHn3tmOs4AABgkrYfblYobBnHGEVhRlRcOydH96wo0T/vOKHGzn7X\ncQAAwCRsqWlUbnqSVs7NdR0lJlCYETV/cGeFQuGw/tfLh11HAQAAExQaDuvVQ836SEWh/D7jOk5M\noDAjaubmp+tXbyzVM9V1OtzY5ToOAACYgOpT7TrfN8Q4xjgUZkTV/3XbImWkBPRXzx90HQUAAEzA\n1tpGJft9WlcedB0lZlCYEVW5Gcn6zVsXaevBJr1xrNV1HAAAcJW21jbphgV5ykwJuI4SMyjMiLqH\n1pRqZnaq/uL5WoXDHJkNAIBXHGvu1vGWHsYxLsAfHRB1qUl+/d7Gxfq9H72nn73foHuvmek6EgAA\ncat/aFg2SvenXjxwTtLIGQv4OQozpsQvXzdL39l5Qt944aDuXFqklIDfdSQAAOLOD944qa/+x4Go\nvmZFcZZm56ZH9TW9jsKMKeH3GX1lc4U+99hu/fCNU/q1tQtcRwIAIK6EhsP6x23HVFkyQ/deG73f\n5t6yqCBqrxUvKMyYMuvKg1pbVqBvvnJUn7p+jrLTk1xHAgAgbrx4oFFnz/frzz66THdwhPWUYtEf\nptSXN1eos39I/7DtqOsoAADElcdeP6F5+em6rYJ546lGYcaUWjozWx+7bpYe33VSdW29ruMAABAX\n3q3r0N5T7fr8zaWcxjcNKMyYcv9942Il+3369R9Uq7N/yHUcAAA877GdJ5SVEtCnqua4jpIQKMyY\ncjNz0vQPv7JSR5u69Zv/8rYGQ2HXkQAA8KyG83167v0GfXrVHA4XmSYUZkyLdeVB/cXHl2vn0RZ9\n5Sfvy0Zrw0gAABLMD984pbC1evDmUtdREgZ/LMG0+VTVHJ3p6NPfbTmiWblp+t07yl1HAgDAU/oG\nh/XE7tPaWFmsOXnslTxdKMyYVr+zoUxn2vv0/209otk5abpvFbNXAABE6ifv1Kujd0hfWDvfdZSE\nQmHGtDLG6M8/vlznOvv1lX9/X0XZqVpfHnQdCwCAmBcOWz2284SWz8pW1bxc13ESCjPMmHZJfp/+\n4VdWqrwoS7/5L3t14Ox515EAAIh5O4626Fhzjx6+pVTGsJXcdKIww4ms1CQ9/vlVmpGWpIce36Mz\nHX2uIwEAENMe23lCwawU3b08esdgIzIRFWZjzCZjzCFjzFFjzJcv8v0UY8zTo99/yxhTOvp4qTGm\nzxjz7ujHP0Y3PrysODtVjz+0Sn2Dw3ro8d0638cezQAAXMzRpi69drhZn7txnpID3O+cblf8K26M\n8Uv6lqTNkiolPWCMqbzgsi9IarfWLpL0vyT91bjvHbPWXjv68aUo5UacqCieoX/61et1oqVHX/rh\nXvZoBgDgIh57/aRSAj595oa5rqMkpEj+iLJa0lFr7XFr7aCkpyR99IJrPirp+6Of/1jSBsNwDSJ0\n86IC/dUnVuiN4636w3/bxx7NAACM094zqJ+8Xa+PXTdL+ZkpruMkpEgK8yxJdeO+rh997KLXWGtD\nks5Lyh/93nxjzDvGmNeMMWsv9gbGmC8aY6qNMdXNzc1X9QMgPnx85Wz9943l+vd3zuhvXjrsOg4A\nADHjyT2n1T8U1kNr2ErOlaneVq5B0lxrbasx5npJ/9sYs9Ra2zn+Imvto5IelaSqqipuLyao3/rI\nItW39+n/f/WoZuWm6YHV/NoJAJDYhobD+sGuU7plUYEWF2e5jpOwIrnDfEbS+NMlZo8+dtFrjDEB\nSdmSWq21A9baVkmy1u6VdEwSx7vhoowx+p+/vEzry4P6H/97v1491OQ6EgAATj33foPOdfbr4VtK\nXUdJaJEU5j2Syowx840xyZLul/TTC675qaQHRz//pKRXrLXWGBMcXTQoY8wCSWWSjkcnOuJRwO/T\nt35lpSqKs/Rb//q29p9hj2YAQGKyduSgkgUFGbq1vNB1nIR2xcI8OpP8iKQXJdVKesZae8AY8zVj\nzL2jl31XUr4x5qik35U0tvXcOkn7jDHvamQx4JestW3R/iEQXzJTAnr886uUm56sh763R3Vtva4j\nAQAw7d4+3aH36s/roTWl8vnYS8ElE2s7ElRVVdnq6mrXMRADjjR26RPf3qXCGan6ty/drOz0JNeR\nAACYNr/1xNvacbhZb3xlgzJSpnrZWWIyxuy11lZd6Tp2vkbMKivK0qOfq9Lp1l598YfVGggNu44E\nAMC0ONPRpxf2n9MDq+dSlmMAhRkx7cYF+frrT63QWyfa9Ps/2qdwOLZ+IwIAwFT4wa6TkqTP3Vzq\nNAdG8EcWxLyPXjtLZzv69VcvHNSs3DT94aYK15EAAJgyPQMhPbn7tDYtK9asnDTXcSAKMzziS+sX\n6ExHr7697Zhm5aTpszfOcx0JAIAp8ZO369XZH9LDHFQSMyjM8ARjjP70l5aqoaNfX/2P/SrJTtWG\nJUWuYwEAEFXhsNXjr5/UNXNytHJujus4GMUMMzwj4Pfpm5+5TstmZeuRJ97RvvoO15EAAIiqbYeb\ndLylRw+vKZUxbCUXKyjM8JT05IC+++Aq5Wcm62H2aAYAxJnHdp5U8YxU3bW8xHUUjENhhucEs1L0\nvYdWa2jY6sHHd6ujd9B1JAAAJu3QuS7tPNqiz908T0l+Klos4e8GPGlRYab++XNVqm/v06//oFr9\nQ+zRDADwtsdfP6HUJJ8eWDXXdRRcgMIMz1o9P09/e9812nOyXb/3o/fYoxkA4Fmt3QP6yTtn9PGV\ns5Wbkew6Di7ALhnwtHtWzNTZjj79+XMHNSsnTX901xLXkQAAuGpPvHVag6GwHl5T6joKLoLCDM/7\n9bULdKa9T49uP65ZOWl6kFORAAAeMhgK6wdvntL68qAWFWa5joOLoDDD84wx+uovLdWZjn792X8e\nUEl2qjYuLXYdCwCAiDz7/lk1dw3o4U9xUEmsYoYZccHvM/rmA9dp+ewc/fZT7+id0+2uIwEAcEXW\nWn135wktKszUurIC13FwCRRmxI20ZL+++2CVCrNS9Wvfr9ap1h7XkQAAuKzqU+3af6ZTD3FQSUyj\nMCOuFGSm6HsPrVLYWn3+8T1q62GPZgBA7PrujhPKSU/Sx6+b7ToKLoPCjLizIJip7zxYpTMd7NEM\nAIhddW29eqnmnD6zeq7Skv2u4+AyKMyIS9fPy9Pff/pavX26Xf/t6Xc1zB7NAIAY8/1dJ+UzRr96\n0zzXUXAFFGbErc3LS/THdy3R8/vP6c+fq3UdBwCAD3QPhPT0njrdtbxEJdlpruPgCthWDnHt19Yu\n0JmOPn135wnNyknTw7ewZQ8AwL0fVdepayDEf5c8gsKMuPc/7q7U2Y4+ff3ZGs3MSdWmZSWuIwEA\nEthw2Op7u07q+nm5unZOjus4iAAjGYh7fp/R399/na6dk6Pfeepd7T3V5joSACCBvXKwSadae/Xw\nGu4uewV3mJEQUpP8+s7nqvSJb+/Sr32/Wj/5zTWaX5DhOhaAONPVP6Su/pDrGIhx39lxXDOzU3Xn\n0iLXURAhCjMSRn5mir730Gp9/Nu79PnHd+snv3Gz8jNTXMcCECfaega1/huvqmuAwowr+8rmCgX8\n/KLfKyjMSCilBRn6zoNVeuDRN/WF71fryV+/kb0vAUTFk7tPq2sgpP/7nkplpvDvFVxakt+nu1ew\nnsZLKMxIOCvn5urv779Ov/Gve/U7T72jb3/2evl9HEcKYOIGQ2F9f9dJrS0r0BfY9QCIO/wuAAlp\n07JiffWeSr1U06iv/6xG1nKwCYCJe+79BjV1DVCWgTjFHWYkrIfWzNeZ9j59Z+cJDYSGtaGiSNfP\ny1VuRrLraAA8xFqrx14/oYXBDK0rC7qOA2AKUJiR0P7oriXqHgjpx3vr9eTuOknSgmCGrp+bq6rS\nXF0/L1cLCjLlY2QDwCXsPdWuffXn9T9/eRn/rgDiFIUZCc3nM/rLT6zQn967VPvqz2vvqXbtPdWm\nLbWN+tHeeklSTnqSVs4dKc/Xz8vVNbNzWCgI4AOPvX5C2WlJ+vjKWa6jAJgiFGZAI/s0r56fp9Xz\n8yQtlLVWJ1p6VH2qXW+falf1qXa9crBJkhTwGVXOnPFBgb5+Xq5KstPc/gAAnKhr69UL+8/pi+sW\nKj2Z/6QC8Yp/uoGLMMZoQTBTC4KZuq9qjiSpo3dQ75zuUPWpNu091a4nd5/W46+flCTNyknTynm5\nqpqXq5Vzc5WTnhS1LDNSk5QdxdcDED0/eOOkjDF68OZ5rqMAmEIUZiBCOenJ+khFoT5SUShJGhoO\nq7ahU3tH70DvOdGm/3zvbNTfNy3Jrx//xk1aOjM76q8NYOK6B0J6ak+d7lpewm+ZgDhHYQYmKMnv\n04rZOVoxO0cPrRnZSupMR5/eq+tQ7+BwVN7DWqv/57la/eXzB/XDL9wQldcEEB3/trdeXf0hPbym\n1HUUAFOMwgxE0aycNM3Kie6dps7+kL7+sxq9drhZ68vZsgqIBeGw1eOvn9B1c3N03dxc13EATDEO\nLgFi3GdvnKs5eWn6i+dqNRzmgBUgFrxysEknW3v18BoOKgESAYUZiHEpAb9+/84KHTzXpX9/54zr\nOAA0spXczOxUbV5W7DoKgGlAYQY84J7lJbpmdrb+5qVD6h+Kznw0gImpbejUrmOt+tzNpQr4+c8o\nkAj4Jx3wAJ/P6Mubl6jhfL8ee/2E6zhAQnts5wmlJfl1/6o5rqMAmCYUZsAjblqYrw0Vhfr2q8fU\n1jPoOg6QkFq6B/Qf757VJ66fpZz0ZNdxAEwTCjPgIV/eXKGewZC++coR11GAhPSvb57W4HD4g60k\nASQGCjPgIWVFWfr0qjn6lzdP6VRrj+s4QEIZCA3rh2+e0kcWB7UwmOk6DoBpRGEGPOa/3l6ugM+n\nb7x4yHUUIKH853sNauke0MO3cHcZSDQUZsBjimak6tfXztez+xr0zul213GAhGCt1WM7T6isMFO3\nLCpwHQfANKMwAx70xfULVZCZrL94/qCs5TATYKq9daJNNQ2deviW+TLGuI4DYJpRmAEPykwJ6Hdu\nL9fuE23aUtvkOg4Q9x7beUK56Un62HWzXEcB4ACFGfCo+1fN0YKCDP3l87UKDYddxwHi1qnWHr1c\n26hfuWGeUpP8ruMAcIDCDHhUkt+nP9hUoWPNPXqmut51HCBufW/XSfmN0a/eNM91FACOUJgBD7tz\naZGq5uXqb18+rJ6BkOs4QNzp6h/Sj6rrdc+KEhXNSHUdB4AjFGbAw4wx+spdS9TSPaB/3nHcdRwg\n7jxTXa/ugZC+cMsC11EAOERhxv9p7+6D5arrO46/v7lJCA8JwUTAPJDEEB4CFpBbQLQVQQR0CMxQ\nKhmYkkJ1KASnLdri6DCM7bQGZ3ScirappjgqDQ/TYiwg0gjSBBISMBQI5AEuDwEkIQkJJTzk4ds/\n9lCXFPaeS+/ds3f3/frn7p79nd3Pvd85u9/53XP2p0Hu2En7ccaRBzL3nidZ/8rrVceR2sbOXcl1\n9/bwu5P340MT9q06jqQK2TBLbeAvTz+MN3fs4tv/4ZLZUn+5c+WLPLvpNS5yGWyp49kwS21gyti9\nOf/4g5i/7FnWrv/vquNIbWHe4h7Gj96TU6cfUHUUSRWzYZbaxOWnTGPPYV3M+fnjVUeRBr1HntvC\n/T2bmHXiZIZ2+VEpdTrfBaQ2MXafPbjk4x/kzpUvcn/PpqrjSIPavMU97D28i88eN7HqKJJagA2z\n1EYu/tgHOWDUHvztbY+5ZLb0Hq3f+jo/e+h5zu2eyKgRw6qOI6kF2DBLbWTP4V1cceqhrHj2ZW57\n+DdVx5EGpR8veZodu5ILT5xcdRRJLcKGWWoz5xw7gUMO2Idr7nicN3e4ZLbUF69v38mPlz7DKYft\nz5Sxe1cdR1KLsGGW2kzXkODLZxzO0xu3cf3Sp6uOIw0qC1Y8z6ZX3/Sr5CS9jQ2z1IZOOvT9nDh1\nDN9euIatr2+vOo40KGQm8xb3cNiBI/nI1DFVx5HUQmyYpTYUUZtl3rxtO/9w9xNVx5EGhXuf2Mjj\nv3mFiz42hYioOo6kFmLDLLWpD03Yl7OOHscPFvXwwpbXqo4jtbx5i3oYs/dwZhw1ruooklqMDbPU\nxr74qUPJhG/+YnXVUaSW1vPSqyx8fD3nnzCJEcO6qo4jqcXYMEttbOL79uLCEydx84PreOyFrVXH\nkVrWPy/uYXjXEC444aCqo0hqQTbMUpu77BMHM3KPoXz9dpfMlt7Jlm3buWn5Os48ahz7jxxRdRxJ\nLahUwxwRp0fEqohYGxFXvsPje0TEDcXjSyNict1jXy62r4qI0/ovuqQyRu81nNknH8yvVm9g0ZqX\nqo4jtZwblj/Da9t38scfnVx1FEktqteGOSK6gGuBM4DpwMyImL7bsIuBzZl5MPAtYE6x73TgPOAI\n4HTgu8XzSWqiP/rIZJGIVBIAAAjhSURBVMaP3pO/u/0xdu1yyWzpLTt27uKH9z7N8VPex5Hj9606\njqQWNbTEmOOAtZn5JEBEzAfOAlbWjTkLuLq4fTPwnah9J89ZwPzMfAPoiYi1xfPd1z/xJZUxYlgX\nXzrtUP7shhXMW9zjd8xKheVPbea5l1/jqjN3nweSpN8q0zCPB56tu78OOP7dxmTmjojYAowpti/Z\nbd/x7zmtpPdsxlHj+P6iJ/mbWx+rOorUUiaN2YtPHn5A1TEktbAyDfOAi4jPA58HOOggr1CWBsKQ\nIcH1nzuB+57YWHUUqaVM/8Aouoa4UImkd1emYX4OmFh3f0Kx7Z3GrIuIocC+wMaS+5KZc4G5AN3d\n3Z5gKQ2QUSOGcdoRB1YdQ5KkQaXMt2QsA6ZFxJSIGE7tIr4Fu41ZAFxY3P4D4JeZmcX284pv0ZgC\nTAPu75/okiRJ0sDrdYa5OCd5NnAH0AXMy8xHI+JrwPLMXAD8APhRcVHfJmpNNcW4G6ldILgDuCwz\ndw7Q7yJJkiT1u6hNBLeO7u7uXL58edUxJEmS1OYi4oHM7O5tnCv9SZIkSQ3YMEuSJEkN2DBLkiRJ\nDdgwS5IkSQ3YMEuSJEkN2DBLkiRJDdgwS5IkSQ3YMEuSJEkN2DBLkiRJDdgwS5IkSQ3YMEuSJEkN\n2DBLkiRJDdgwS5IkSQ3YMEuSJEkN2DBLkiRJDdgwS5IkSQ3YMEuSJEkNRGZWneFtIuIVYFXVOQTA\nWOClqkPIOrQQa9EarEPrsBatwTq8d5My8/29DRrajCR9tCozu6sOIYiI5daietahdViL1mAdWoe1\naA3WYeB5SoYkSZLUgA2zJEmS1EArNsxzqw6g/2UtWoN1aB3WojVYh9ZhLVqDdRhgLXfRnyRJktRK\nWnGGWZIkSWoZlTXMEXF6RKyKiLURceU7PP4XEbEyIv4rIhZGxKQqcnaCErW4JCIejogVEbEoIqZX\nkbPd9VaHunHnRERGhFdED5ASx8SsiNhQHBMrIuJPqsjZ7socExHxh8VnxaMRcX2zM3aCEsfDt+qO\nhdUR8XIVOTtBiVocFBF3RcSvi/7p01XkbEeVnJIREV3AauBUYB2wDJiZmSvrxnwCWJqZ2yLiT4GT\nMvOzTQ/b5krWYlRmbi1uzwAuzczTq8jbrsrUoRg3ErgVGA7Mzszlzc7a7koeE7OA7sycXUnIDlCy\nDtOAG4GTM3NzROyfmesrCdymyr431Y2/HDgmMy9qXsrOUPKYmAv8OjO/V0xu3ZaZk6vI226qmmE+\nDlibmU9m5pvAfOCs+gGZeVdmbivuLgEmNDljpyhTi611d/cGPPG9//Vah8JfA3OA15sZrsOUrYUG\nVpk6fA64NjM3A9gsD4i+Hg8zgX9pSrLOU6YWCYwqbu8LPN/EfG2tqoZ5PPBs3f11xbZ3czFw+4Am\n6lylahERl0XEE8A1wBealK2T9FqHiPgwMDEzb21msA5U9v3pnOJfnjdHxMTmROsoZepwCHBIRCyO\niCUR4X+++l/pz+vi1MkpwC+bkKsTlanF1cAFEbEOuA24vDnR2l/LX/QXERcA3cA3qs7SyTLz2syc\nCvwV8NWq83SaiBgCfBO4ouosAuBnwOTM/B3gTuCHFefpVEOBacBJ1GY2/ykiRleaqLOdB9ycmTur\nDtLBZgLXZeYE4NPAj4rPD/0/VfVHfA6on5GZUGx7m4j4JPAVYEZmvtGkbJ2mVC3qzAfOHtBEnam3\nOowEjgTujoingBOABV74NyB6PSYyc2Pde9L3gWOblK2TlHlvWgcsyMztmdlD7fzOaU3K1yn68hlx\nHp6OMZDK1OJiauf1k5n3ASOAsU1J1+aqapiXAdMiYkpEDKd2kC2oHxARxwD/SK1Z9ry0gVOmFvUf\nQJ8B1jQxX6doWIfM3JKZYzNzcnEBxxJqx4YX/fW/MsfEB+ruzgAea2K+TtFrHYBbqM0uExFjqZ2i\n8WQzQ3aAMnUgIg4D9gPua3K+TlKmFs8ApwBExOHUGuYNTU3ZpoZW8aKZuSMiZgN3AF3AvMx8NCK+\nBizPzAXUTsHYB7gpIgCeycwZVeRtZyVrMbuY7d8ObAYurC5xeypZBzVByVp8ofjGmB3AJmBWZYHb\nVMk63AF8KiJWAjuBL2XmxupSt58+vDedB8xPV0MbMCVrcQW1U5P+nNoFgLOsSf9wpT9JkiSpAU8E\nlyRJkhqwYZYkSZIasGGWJEmSGrBhliRJkhqwYZYkSZIasGGWpCaJiNERcWlx+6SI+PcBeI1ZEfGd\nPu7zVPE9xrtvvzoivth/6SRpcLJhlqTmGQ1c2pcdIqJrgLJIkkqyYZak5vk6MDUiVlAszhQRN0fE\n4xHxkyhWaSpmfOdExIPAuRExNSJ+HhEPRMR/FquqERHnRsQjEfFQRNxT9zrjivFrIuKatzZGxMyI\neLjYZ847BYyIr0TE6ohYBBw6UH8ISRpMKlnpT5I61JXAkZl5dEScBPwUOAJ4HlgMfBRYVIzdmJkf\nBoiIhcAlmbkmIo4HvgucDFwFnJaZz0XE6LrXORo4BngDWBURf09tJbw5wLHUVuz8RUScnZm3vLVT\nRBxLbcW2o6l9PjwIPND/fwZJGlxsmCWpOvdn5jqAYtZ5Mr9tmG8otu8DnAjcVExAA+xR/FwMXBcR\nNwL/Wve8CzNzS7H/SmASMAa4OzM3FNt/Avw+cEvdfr8H/FtmbivGuCS7JGHDLElVeqPu9k7e/p78\navFzCPByZh69+86ZeUkx4/wZ4IFihri355Uk9ZHnMEtS87wCjOzLDpm5FeiJiHMBouao4vbUzFya\nmVcBG4CJDZ7qfuDjETG2uJBwJvCr3cbcA5wdEXtGxEjgzL5klaR25ayDJDVJZm6MiMUR8QjwGvBi\nyV3PB74XEV8FhgHzgYeAb0TENCCAhcW2/zMTXbz2CxFxJXBXMf7WzPzpbmMejIgbiudZDyzr6+8o\nSe0oMrPqDJIkSVLL8pQMSZIkqQEbZkmSJKkBG2ZJkiSpARtmSZIkqQEbZkmSJKkBG2ZJkiSpARtm\nSZIkqQEbZkmSJKmB/wF8ZY/nRgzz3AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot IoU values over threshold range.\n",
    "df_iou.plot(x='threshold', y='iou')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "msQmmcjH_EpX"
   },
   "source": [
    "## Conclusions:\n",
    "\n",
    "- Pretrained models can be used for segmentation problems:\n",
    "    - Some of architectures can be easily adapted to the problem (ie ResNet)\n",
    "    - Other architectures may require more experimentation with selection of proper layers for feature extraction and padding (example of using [Xception](https://www.kaggle.com/meaninglesslives/getting-0-87-on-private-lb-using-kaggle-kernel). )\n",
    "    - You can experiment with selection of layers for feature extraction\n",
    "    - For some models, you can also try to experiment with number of encoder/decoder blocks\n",
    "- Threshold optimization is important in problems, where direct metric optimization during training is difficult.\n",
    "    - It it possible to use more involved optimization methods (from [scipy optimize](https://docs.scipy.org/doc/scipy/reference/optimize.html)), although this may not be optimal unless distribution of train and test set are very similar. Overoptimization of threshold or any other parameter on validation set may result in worse test set results.\n",
    "- Experiment with various losses - BCE, Dice, combined BCE with Dice, Lovash loss.\n",
    "    - Models trained with various losses may give different results, which may be advantageous when ensembling.\n",
    "\n",
    "\n",
    "### Possible experiments:\n",
    "\n",
    "- Change type of decoder block in created segmentation model\n",
    "- Create your own decoder blocks\n",
    "- Train with other losses\n",
    "- Train longer\n",
    "- Train with BCE/Dice, save the model, then load weights and finetune with Lovash loss\n",
    "- Try different ranges and intervals for threshold optimization\n",
    "\n",
    "##結論：\n",
    "\n",
    "-事前学習済みのモデルは、セグメンテーションの問題に使用できます。\n",
    "    -一部のアーキテクチャは、問題に簡単に適合させることができます（ResNetなど）\n",
    "    -他のアーキテクチャでは、機能の抽出とパディングに適切なレイヤーを選択するためのより多くの実験が必要になる場合があります（[Xception]（https://www.kaggle.com/meaninglesslives/getting-0-87-on-private-lb-usingの使用例） -kaggle-kernel）。）\n",
    "    -特徴抽出用のレイヤーの選択を試すことができます\n",
    "    -一部のモデルでは、エンコーダー/デコーダーブロックの数を試してみることができます\n",
    "-トレーニング中の直接的なメトリック最適化が難しい問題では、しきい値の最適化が重要です。\n",
    "    -より複雑な最適化方法を使用することが可能です（[scipy optimize]（https://docs.scipy.org/doc/scipy/reference/optimize.html）から）。ただし、これは列車とテストセットは非常に似ています。検証セットのしきい値またはその他のパラメーターを過剰に最適化すると、テストセットの結果が悪化する可能性があります。\n",
    "-さまざまな損失の実験-BCE、Dice、BCEとDice、Lovashの損失の組み合わせ。\n",
    "    -さまざまな損失で訓練されたモデルは異なる結果をもたらす可能性があり、これは組み立てるときに有利になる場合があります。\n",
    "\n",
    "\n",
    "###可能な実験：\n",
    "\n",
    "-作成されたセグメンテーションモデルのデコーダブロックのタイプを変更\n",
    "-独自のデコーダーブロックを作成\n",
    "-他の損失を伴う訓練\n",
    "-より長くトレーニング\n",
    "-BCE / Diceでトレーニングし、モデルを保存してから、Lovashの損失で重量をロードして微調整します\n",
    "-しきい値の最適化のために異なる範囲と間隔を試してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w39PrYcx_EpY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "03-models_pretrained_and_more (2)_VGGNET.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
