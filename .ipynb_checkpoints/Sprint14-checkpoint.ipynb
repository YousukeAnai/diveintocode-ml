{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題1】公式Exampleを分担して実行¶\n",
    "TensorFLowの公式Exampleを分担して実行してください。\n",
    "以下の中から1人ひとつ選び実行し、その結果を簡単に発表してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"A binary to train CIFAR-10 using a single GPU.\n",
    "Accuracy:\n",
    "cifar10_train.py achieves ~86% accuracy after 100K steps (256 epochs of\n",
    "data) as judged by cifar10_eval.py.\n",
    "Speed: With batch_size 128.\n",
    "System        | Step Time (sec/batch)  |     Accuracy\n",
    "------------------------------------------------------------------\n",
    "1 Tesla K20m  | 0.35-0.60              | ~86% at 60K steps  (5 hours)\n",
    "1 Tesla K40m  | 0.25-0.35              | ~86% at 100K steps (4 hours)\n",
    "Usage:\n",
    "Please see the tutorial and website for how to download the CIFAR-10\n",
    "data set, compile the program and train the model.\n",
    "http://tensorflow.org/tutorials/deep_cnn/\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from datetime import datetime\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import cifar10\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "tf.app.flags.DEFINE_string('train_dir', '/tmp/cifar10_train',\n",
    "                           \"\"\"Directory where to write event logs \"\"\"\n",
    "                           \"\"\"and checkpoint.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('max_steps', 100000,\n",
    "                            \"\"\"Number of batches to run.\"\"\")\n",
    "tf.app.flags.DEFINE_boolean('log_device_placement', False,\n",
    "                            \"\"\"Whether to log device placement.\"\"\")\n",
    "tf.app.flags.DEFINE_integer('log_frequency', 10,\n",
    "                            \"\"\"How often to log results to the console.\"\"\")\n",
    "def train():\n",
    "  \"\"\"Train CIFAR-10 for a number of steps.\"\"\"\n",
    "\n",
    "  with tf.Graph().as_default():\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "    # Get images and labels for CIFAR-10.\n",
    "    # Force input pipeline to CPU:0 to avoid operations sometimes ending up on\n",
    "    # GPU and resulting in a slow down.\n",
    "    \n",
    "    with tf.device('/cpu:0'):\n",
    "      images, labels = cifar10.distorted_inputs()\n",
    "\n",
    "    # Build a Graph that computes the logits predictions from the\n",
    "    # inference model.\n",
    "\n",
    "    logits = cifar10.inference(images)\n",
    "\n",
    "    # Calculate loss.\n",
    "    loss = cifar10.loss(logits, labels)\n",
    "\n",
    "    # Build a Graph that trains the model with one batch of examples and\n",
    "    # updates the model parameters.\n",
    "\n",
    "    train_op = cifar10.train(loss, global_step)\n",
    "\n",
    "    class _LoggerHook(tf.train.SessionRunHook):\n",
    "      \"\"\"Logs loss and runtime.\"\"\"\n",
    "\n",
    "      def begin(self):\n",
    "\n",
    "        self._step = -1\n",
    "        self._start_time = time.time()\n",
    "\n",
    "      def before_run(self, run_context):\n",
    "\n",
    "        self._step += 1\n",
    "        return tf.train.SessionRunArgs(loss)  # Asks for loss value.\n",
    "\n",
    "      def after_run(self, run_context, run_values):\n",
    "\n",
    "        if self._step % FLAGS.log_frequency == 0:\n",
    "          current_time = time.time()\n",
    "          duration = current_time - self._start_time\n",
    "          self._start_time = current_time\n",
    "\n",
    "          loss_value = run_values.results\n",
    "          examples_per_sec = FLAGS.log_frequency * FLAGS.batch_size / duration\n",
    "          sec_per_batch = float(duration / FLAGS.log_frequency)\n",
    "\n",
    "          format_str = ('%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '\n",
    "                        'sec/batch)')\n",
    "\n",
    "          print (format_str % (datetime.now(), self._step, loss_value,\n",
    "                               examples_per_sec, sec_per_batch))\n",
    "\n",
    "    with tf.train.MonitoredTrainingSession(\n",
    "\n",
    "        checkpoint_dir=FLAGS.train_dir,\n",
    "        hooks=[tf.train.StopAtStepHook(last_step=FLAGS.max_steps),\n",
    "               tf.train.NanTensorHook(loss),\n",
    "               _LoggerHook()],\n",
    "        config=tf.ConfigProto(\n",
    "            log_device_placement=FLAGS.log_device_placement)) as mon_sess:\n",
    "\n",
    "      while not mon_sess.should_stop():\n",
    "\n",
    "        mon_sess.run(train_op)\n",
    "\n",
    "def main(argv=None):  # pylint: disable=unused-argument\n",
    "\n",
    "  if tf.gfile.Exists(FLAGS.train_dir):\n",
    "    tf.gfile.DeleteRecursively(FLAGS.train_dir)\n",
    "  tf.gfile.MakeDirs(FLAGS.train_dir)\n",
    "  train()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "  tf.app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 問題2】Iris（2値分類）をKerasで学習¶\n",
    "TensorFlowによるIrisデータセットに対する2値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 50)                250       \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 5,451\n",
      "Trainable params: 5,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 64 samples, validate on 16 samples\n",
      "Epoch 1/10\n",
      "64/64 - 0s - loss: 0.7047 - acc: 0.5781 - val_loss: 0.7205 - val_acc: 0.3750\n",
      "Epoch 2/10\n",
      "64/64 - 0s - loss: 0.5705 - acc: 0.7031 - val_loss: 0.5153 - val_acc: 0.9375\n",
      "Epoch 3/10\n",
      "64/64 - 0s - loss: 0.4606 - acc: 0.8594 - val_loss: 0.3898 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      "64/64 - 0s - loss: 0.3550 - acc: 0.9375 - val_loss: 0.2966 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "64/64 - 0s - loss: 0.2539 - acc: 0.9688 - val_loss: 0.2812 - val_acc: 0.8750\n",
      "Epoch 6/10\n",
      "64/64 - 0s - loss: 0.3398 - acc: 0.8281 - val_loss: 0.4318 - val_acc: 0.8125\n",
      "Epoch 7/10\n",
      "64/64 - 0s - loss: 0.3237 - acc: 0.8438 - val_loss: 0.1511 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "64/64 - 0s - loss: 0.2358 - acc: 0.9219 - val_loss: 0.1435 - val_acc: 0.9375\n",
      "Epoch 9/10\n",
      "64/64 - 0s - loss: 0.1266 - acc: 0.9688 - val_loss: 0.1410 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "64/64 - 0s - loss: 0.1007 - acc: 0.9844 - val_loss: 0.1572 - val_acc: 0.8750\n",
      "y_pred [0 1 0 1 1 1 0 0 1 1 1 1 1 0 0 0 0 0 1 0]\n",
      "Test loss: 0.17339585721492767\n",
      "Test accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "th.kerasで実装したニューラルネットワークを使いIrisデータセットを2値分類する\n",
    "\"\"\"\n",
    "# データセットの読み込み\n",
    "#dataset_path = r\"Iris.csv\"\n",
    "df = pd.read_csv(r\"C:\\Users\\anai\\dive\\Dataset\\iris\\iris.csv\")\n",
    "# データフレームから条件抽出\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "y = y.astype(np.int)[:, np.newaxis]\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 1\n",
    "\n",
    "input_data = tf.keras.layers.Input(shape=(n_input,))\n",
    "x = tf.keras.layers.Dense(n_hidden1, activation=tf.nn.relu)(input_data)\n",
    "x = tf.keras.layers.Dense(n_hidden2, activation=tf.nn.relu)(x)\n",
    "output = tf.keras.layers.Dense(n_classes, activation=tf.nn.sigmoid)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=10,\n",
    "                    epochs=10,\n",
    "                    verbose=2,\n",
    "                   validation_data=(X_val, y_val))\n",
    "\n",
    "y_pred_proba = model.predict(X_test)[:, 0]\n",
    "\n",
    "# 確率を0, 1に変換\n",
    "y_pred = np.where(y_pred_proba >0.5, 1, 0)\n",
    "\n",
    "#print(\"y_pred_proba\", y_pred_proba)\n",
    "print(\"y_pred\", y_pred)\n",
    "#結果がいらず、評価のみ行う場合はevaluateメソッドも便利です。\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題3】Iris（多値分類）をKerasで学習\n",
    "TensorFlowによるIrisデータセットに対する3値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 50)                250       \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 5,653\n",
      "Trainable params: 5,653\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 96 samples, validate on 24 samples\n",
      "Epoch 1/10\n",
      "96/96 - 0s - loss: 0.9051 - acc: 0.6667 - val_loss: 0.4821 - val_acc: 0.8750\n",
      "Epoch 2/10\n",
      "96/96 - 0s - loss: 0.5359 - acc: 0.7396 - val_loss: 0.4789 - val_acc: 0.6250\n",
      "Epoch 3/10\n",
      "96/96 - 0s - loss: 0.2989 - acc: 0.8750 - val_loss: 0.3015 - val_acc: 0.9583\n",
      "Epoch 4/10\n",
      "96/96 - 0s - loss: 0.2036 - acc: 0.9479 - val_loss: 0.3081 - val_acc: 0.9167\n",
      "Epoch 5/10\n",
      "96/96 - 0s - loss: 0.1371 - acc: 0.9583 - val_loss: 0.2003 - val_acc: 0.9167\n",
      "Epoch 6/10\n",
      "96/96 - 0s - loss: 0.1222 - acc: 0.9479 - val_loss: 0.6565 - val_acc: 0.7083\n",
      "Epoch 7/10\n",
      "96/96 - 0s - loss: 0.3188 - acc: 0.8646 - val_loss: 0.2564 - val_acc: 0.8750\n",
      "Epoch 8/10\n",
      "96/96 - 0s - loss: 0.1502 - acc: 0.9167 - val_loss: 0.3195 - val_acc: 0.8333\n",
      "Epoch 9/10\n",
      "96/96 - 0s - loss: 0.2152 - acc: 0.9062 - val_loss: 0.1834 - val_acc: 0.9167\n",
      "Epoch 10/10\n",
      "96/96 - 0s - loss: 0.1335 - acc: 0.9479 - val_loss: 0.3738 - val_acc: 0.9167\n",
      "y_pred_proba [[2.4485013e-08 1.3733081e-03 9.9862671e-01]\n",
      " [3.1426186e-03 9.4922310e-01 4.7634374e-02]\n",
      " [9.9965036e-01 3.4949434e-04 6.3319533e-08]\n",
      " [2.2509392e-08 3.8588629e-03 9.9614114e-01]\n",
      " [9.9844700e-01 1.5521487e-03 8.4788246e-07]\n",
      " [2.4453342e-09 5.5827608e-04 9.9944168e-01]\n",
      " [9.9881208e-01 1.1872979e-03 6.1303240e-07]\n",
      " [8.8776182e-04 8.1987303e-01 1.7923926e-01]\n",
      " [4.6709436e-04 7.6418066e-01 2.3535231e-01]\n",
      " [4.9934122e-03 9.5243669e-01 4.2569898e-02]\n",
      " [4.7165861e-07 1.1466560e-02 9.8853302e-01]\n",
      " [1.7550330e-03 8.5447878e-01 1.4376615e-01]\n",
      " [7.6506648e-04 6.9401628e-01 3.0521867e-01]\n",
      " [4.5087782e-04 6.2838340e-01 3.7116572e-01]\n",
      " [3.5755610e-04 4.5854449e-01 5.4109800e-01]\n",
      " [9.9776399e-01 2.2347486e-03 1.3141437e-06]\n",
      " [4.3225498e-04 4.4254407e-01 5.5702370e-01]\n",
      " [6.0452038e-04 4.4986326e-01 5.4953229e-01]\n",
      " [9.9661189e-01 3.3851597e-03 3.0291242e-06]\n",
      " [9.9939024e-01 6.0946541e-04 1.8408532e-07]\n",
      " [3.2288065e-07 4.7768531e-03 9.9522287e-01]\n",
      " [2.5702154e-04 2.4461311e-01 7.5512987e-01]\n",
      " [9.9637467e-01 3.6215030e-03 3.7465934e-06]\n",
      " [9.9580681e-01 4.1874903e-03 5.7558354e-06]\n",
      " [6.6309067e-06 4.1036509e-02 9.5895684e-01]\n",
      " [9.9915063e-01 8.4889325e-04 4.6022171e-07]\n",
      " [9.9782312e-01 2.1751611e-03 1.8145374e-06]\n",
      " [2.8353403e-03 9.1985142e-01 7.7313222e-02]\n",
      " [1.7361728e-02 9.4284731e-01 3.9790932e-02]\n",
      " [9.9738461e-01 2.6132273e-03 2.1913045e-06]]\n",
      "y_pred [[0 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [1 0 0]]\n",
      "Test loss: 0.1862190216779709\n",
      "Test accuracy: 0.8666667\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TensorFlowで実装したニューラルネットワークを使いIrisデータセットを3値分類する\n",
    "\"\"\"\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import sklearn.preprocessing as sp\n",
    "\n",
    "# データセットの読み込み\n",
    "#dataset_path = r\"Iris.csv\"\n",
    "df = pd.read_csv(r\"C:\\Users\\anai\\dive\\Dataset\\iris\\iris.csv\", delimiter=',')\n",
    "# データフレームから条件抽出\n",
    "#df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df['Species']\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-setosa'] = 0\n",
    "y[y=='Iris-versicolor'] = 1\n",
    "y[y=='Iris-virginica'] = 2\n",
    "\n",
    "#onehot\n",
    "#enc = OneHotEncoder(handle_unknown='ignore', sparse=False, dtype='int', categories='auto')\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False, dtype='int')\n",
    "y_1hot = enc.fit_transform(y[:, np.newaxis])\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_1hot, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.01\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 3\n",
    "\n",
    "\n",
    "input_data = tf.keras.layers.Input(shape=(n_input,))\n",
    "x = tf.keras.layers.Dense(n_hidden1, activation=tf.nn.relu)(input_data)\n",
    "x = tf.keras.layers.Dense(n_hidden2, activation=tf.nn.relu)(x)\n",
    "output = tf.keras.layers.Dense(n_classes, activation=tf.nn.softmax)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=10,\n",
    "                    epochs=10,\n",
    "                    verbose=2,\n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "y_pred_proba = model.predict(X_test)[:,:]\n",
    "\n",
    "# 確率を0, 1に変換\n",
    "y_pred = np.where(y_pred_proba >0.5, 1, 0)\n",
    "\n",
    "print(\"y_pred_proba\", y_pred_proba)\n",
    "print(\"y_pred\", y_pred)\n",
    "#結果がいらず、評価のみ行う場合はevaluateメソッドも便利です。\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題4】House PricesをKerasで学習\n",
    "TensorFlowによるHouse Pricesデータセットに対する回帰をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_27 (InputLayer)        [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 50)                150       \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 5,351\n",
      "Trainable params: 5,351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 934 samples, validate on 234 samples\n",
      "Epoch 1/10\n",
      "934/934 - 1s - loss: 37989275819.0321 - mean_squared_error: 37989273600.0000 - val_loss: 32066320541.5385 - val_mean_squared_error: 32066318336.0000\n",
      "Epoch 2/10\n",
      "934/934 - 0s - loss: 13307162597.4133 - mean_squared_error: 13307161600.0000 - val_loss: 3187955385.9829 - val_mean_squared_error: 3187955968.0000\n",
      "Epoch 3/10\n",
      "934/934 - 0s - loss: 3887817920.5482 - mean_squared_error: 3887817984.0000 - val_loss: 3042039058.5983 - val_mean_squared_error: 3042039040.0000\n",
      "Epoch 4/10\n",
      "934/934 - 0s - loss: 3731311677.5332 - mean_squared_error: 3731311104.0000 - val_loss: 2966997929.0256 - val_mean_squared_error: 2966998528.0000\n",
      "Epoch 5/10\n",
      "934/934 - 0s - loss: 3623815897.8330 - mean_squared_error: 3623816960.0000 - val_loss: 2818817159.6581 - val_mean_squared_error: 2818817280.0000\n",
      "Epoch 6/10\n",
      "934/934 - 0s - loss: 3500356463.1777 - mean_squared_error: 3500356096.0000 - val_loss: 2720470555.3504 - val_mean_squared_error: 2720470784.0000\n",
      "Epoch 7/10\n",
      "934/934 - 0s - loss: 3417265689.2163 - mean_squared_error: 3417265920.0000 - val_loss: 2646157560.8889 - val_mean_squared_error: 2646157312.0000\n",
      "Epoch 8/10\n",
      "934/934 - 0s - loss: 3337543566.0814 - mean_squared_error: 3337543680.0000 - val_loss: 2603444890.2564 - val_mean_squared_error: 2603444992.0000\n",
      "Epoch 9/10\n",
      "934/934 - 0s - loss: 3280978803.8030 - mean_squared_error: 3280978944.0000 - val_loss: 2607297986.7350 - val_mean_squared_error: 2607298048.0000\n",
      "Epoch 10/10\n",
      "934/934 - 0s - loss: 3230424103.3319 - mean_squared_error: 3230423552.0000 - val_loss: 2511704461.1282 - val_mean_squared_error: 2511704064.0000\n",
      "y_pred_proba [[268771.66 ]\n",
      " [186490.55 ]\n",
      " [153940.86 ]\n",
      " [226196.97 ]\n",
      " [144770.23 ]\n",
      " [137138.81 ]\n",
      " [178178.62 ]\n",
      " [168648.28 ]\n",
      " [439854.6  ]\n",
      " [146473.19 ]\n",
      " [168364.83 ]\n",
      " [196281.2  ]\n",
      " [223338.92 ]\n",
      " [127958.86 ]\n",
      " [143319.61 ]\n",
      " [163817.4  ]\n",
      " [217919.77 ]\n",
      " [136473.12 ]\n",
      " [156526.25 ]\n",
      " [207515.05 ]\n",
      " [169897.67 ]\n",
      " [124366.664]\n",
      " [120547.125]\n",
      " [179339.1  ]\n",
      " [213361.53 ]\n",
      " [199347.64 ]\n",
      " [187530.05 ]\n",
      " [104535.5  ]\n",
      " [198630.22 ]\n",
      " [155001.97 ]\n",
      " [204221.16 ]\n",
      " [205009.62 ]\n",
      " [129280.805]\n",
      " [242154.94 ]\n",
      " [229070.33 ]\n",
      " [176330.16 ]\n",
      " [186606.34 ]\n",
      " [126518.41 ]\n",
      " [233140.4  ]\n",
      " [279029.1  ]\n",
      " [237407.7  ]\n",
      " [167787.77 ]\n",
      " [164669.   ]\n",
      " [210616.27 ]\n",
      " [293986.06 ]\n",
      " [200176.11 ]\n",
      " [121128.586]\n",
      " [127663.75 ]\n",
      " [196593.45 ]\n",
      " [130040.016]\n",
      " [283256.9  ]\n",
      " [142965.22 ]\n",
      " [166065.9  ]\n",
      " [117555.11 ]\n",
      " [193460.16 ]\n",
      " [125622.84 ]\n",
      " [172954.4  ]\n",
      " [207582.33 ]\n",
      " [147097.52 ]\n",
      " [117818.766]\n",
      " [141261.14 ]\n",
      " [140562.3  ]\n",
      " [157000.22 ]\n",
      " [149832.62 ]\n",
      " [196644.27 ]\n",
      " [178150.98 ]\n",
      " [130118.266]\n",
      " [198155.83 ]\n",
      " [157047.62 ]\n",
      " [201589.06 ]\n",
      " [175306.77 ]\n",
      " [142657.36 ]\n",
      " [131409.89 ]\n",
      " [174245.64 ]\n",
      " [132903.34 ]\n",
      " [194060.38 ]\n",
      " [136449.05 ]\n",
      " [130071.516]\n",
      " [265353.56 ]\n",
      " [162943.75 ]\n",
      " [131420.08 ]\n",
      " [125103.2  ]\n",
      " [165525.42 ]\n",
      " [136473.12 ]\n",
      " [318051.34 ]\n",
      " [166978.77 ]\n",
      " [154026.39 ]\n",
      " [169738.2  ]\n",
      " [156203.48 ]\n",
      " [143397.83 ]\n",
      " [197006.55 ]\n",
      " [187016.83 ]\n",
      " [180849.92 ]\n",
      " [212751.23 ]\n",
      " [160149.25 ]\n",
      " [158561.1  ]\n",
      " [179851.55 ]\n",
      " [194305.36 ]\n",
      " [124901.35 ]\n",
      " [185778.28 ]\n",
      " [201726.52 ]\n",
      " [218107.66 ]\n",
      " [166089.8  ]\n",
      " [174106.69 ]\n",
      " [111308.83 ]\n",
      " [261070.25 ]\n",
      " [168913.5  ]\n",
      " [131615.42 ]\n",
      " [179876.58 ]\n",
      " [166324.72 ]\n",
      " [108667.51 ]\n",
      " [139034.83 ]\n",
      " [223512.22 ]\n",
      " [146234.98 ]\n",
      " [176929.64 ]\n",
      " [184744.44 ]\n",
      " [259185.53 ]\n",
      " [140042.64 ]\n",
      " [236459.72 ]\n",
      " [221416.52 ]\n",
      " [144558.45 ]\n",
      " [171885.84 ]\n",
      " [135466.42 ]\n",
      " [222126.17 ]\n",
      " [188816.02 ]\n",
      " [179452.3  ]\n",
      " [235575.3  ]\n",
      " [163907.44 ]\n",
      " [158663.45 ]\n",
      " [182559.44 ]\n",
      " [167440.39 ]\n",
      " [158576.06 ]\n",
      " [245300.17 ]\n",
      " [175430.39 ]\n",
      " [124901.35 ]\n",
      " [196831.77 ]\n",
      " [178686.95 ]\n",
      " [167952.48 ]\n",
      " [127717.91 ]\n",
      " [189951.81 ]\n",
      " [149482.47 ]\n",
      " [143887.4  ]\n",
      " [246310.14 ]\n",
      " [140395.89 ]\n",
      " [159223.31 ]\n",
      " [181062.08 ]\n",
      " [178353.44 ]\n",
      " [141073.14 ]\n",
      " [203299.73 ]\n",
      " [180575.4  ]\n",
      " [173693.97 ]\n",
      " [199004.81 ]\n",
      " [207544.95 ]\n",
      " [239827.22 ]\n",
      " [193781.33 ]\n",
      " [292678.88 ]\n",
      " [147321.47 ]\n",
      " [180858.86 ]\n",
      " [148115.5  ]\n",
      " [179376.47 ]\n",
      " [124926.586]\n",
      " [152854.78 ]\n",
      " [187942.38 ]\n",
      " [133256.56 ]\n",
      " [187767.58 ]\n",
      " [180608.6  ]\n",
      " [177077.55 ]\n",
      " [254815.2  ]\n",
      " [168839.17 ]\n",
      " [197755.81 ]\n",
      " [169885.72 ]\n",
      " [186242.94 ]\n",
      " [164319.42 ]\n",
      " [149096.55 ]\n",
      " [135289.81 ]\n",
      " [146249.8  ]\n",
      " [148158.97 ]\n",
      " [277820.25 ]\n",
      " [162641.98 ]\n",
      " [144028.6  ]\n",
      " [235961.11 ]\n",
      " [217056.97 ]\n",
      " [145759.77 ]\n",
      " [199154.58 ]\n",
      " [123883.336]\n",
      " [201587.19 ]\n",
      " [135606.5  ]\n",
      " [156827.83 ]\n",
      " [172734.81 ]\n",
      " [124366.664]\n",
      " [136473.12 ]\n",
      " [167625.66 ]\n",
      " [184308.95 ]\n",
      " [129909.04 ]\n",
      " [157172.39 ]\n",
      " [137352.25 ]\n",
      " [104535.5  ]\n",
      " [148458.66 ]\n",
      " [199077.28 ]\n",
      " [168625.14 ]\n",
      " [166027.44 ]\n",
      " [157076.78 ]\n",
      " [116659.555]\n",
      " [140421.1  ]\n",
      " [216454.86 ]\n",
      " [279429.47 ]\n",
      " [158486.39 ]\n",
      " [238221.92 ]\n",
      " [206258.61 ]\n",
      " [123488.44 ]\n",
      " [147517.6  ]\n",
      " [194434.61 ]\n",
      " [139714.64 ]\n",
      " [116778.05 ]\n",
      " [210565.11 ]\n",
      " [257185.8  ]\n",
      " [172795.69 ]\n",
      " [288200.62 ]\n",
      " [194934.38 ]\n",
      " [104585.96 ]\n",
      " [178202.16 ]\n",
      " [170909.86 ]\n",
      " [190696.56 ]\n",
      " [124951.81 ]\n",
      " [181799.38 ]\n",
      " [228945.22 ]\n",
      " [219256.17 ]\n",
      " [214210.11 ]\n",
      " [157100.33 ]\n",
      " [169187.28 ]\n",
      " [139689.42 ]\n",
      " [147646.12 ]\n",
      " [124926.586]\n",
      " [145985.02 ]\n",
      " [211589.64 ]\n",
      " [171932.14 ]\n",
      " [206019.94 ]\n",
      " [121799.62 ]\n",
      " [149607.53 ]\n",
      " [178226.06 ]\n",
      " [160945.17 ]\n",
      " [196419.81 ]\n",
      " [205322.25 ]\n",
      " [206171.22 ]\n",
      " [159748.1  ]\n",
      " [144800.56 ]\n",
      " [168513.47 ]\n",
      " [188416.75 ]\n",
      " [162867.58 ]\n",
      " [175094.25 ]\n",
      " [173943.45 ]\n",
      " [219668.53 ]\n",
      " [123690.29 ]\n",
      " [307370.84 ]\n",
      " [165118.7  ]\n",
      " [210616.3  ]\n",
      " [124444.66 ]\n",
      " [187355.61 ]\n",
      " [336268.34 ]\n",
      " [541133.4  ]\n",
      " [202013.39 ]\n",
      " [180522.36 ]\n",
      " [205781.62 ]\n",
      " [160642.98 ]\n",
      " [232366.53 ]\n",
      " [204623.42 ]\n",
      " [285582.8  ]\n",
      " [ 93876.89 ]\n",
      " [228229.94 ]\n",
      " [198305.6  ]\n",
      " [176825.78 ]\n",
      " [229989.88 ]\n",
      " [180085.36 ]\n",
      " [188140.7  ]\n",
      " [242662.11 ]\n",
      " [232291.45 ]\n",
      " [202874.31 ]\n",
      " [200624.31 ]\n",
      " [220405.06 ]\n",
      " [164814.3  ]\n",
      " [127562.836]\n",
      " [223201.86 ]\n",
      " [179173.98 ]\n",
      " [184842.64 ]\n",
      " [163295.62 ]\n",
      " [235509.89 ]\n",
      " [155802.4  ]\n",
      " [200115.25 ]\n",
      " [260184.69 ]\n",
      " [268684.66 ]\n",
      " [110567.19 ]\n",
      " [145147.8  ]]\n",
      "Test loss: 3833455545.8630137\n",
      "Test accuracy: 3833455600.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TensorFlowで実装したニューラルネットワークを使いHouse Pricesデータセットの価格を推定する。\n",
    "\"\"\"\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# データセットの読み込み\n",
    "df = pd.read_csv(r\"C:\\Users\\anai\\dive\\Dataset\\House Prices\\train.csv\", delimiter=',')\n",
    "#df_test = pd.read_csv(r\"C:\\Users\\anai\\dive\\Dataset\\House Prices\\test.csv\", delimiter=',')\n",
    "\n",
    "# データフレームから条件抽出\n",
    "y = df['SalePrice']\n",
    "X = df.loc[:,[\"GrLivArea\", \"YearBuilt\"]]\n",
    "\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "#std = StandardScaler()\n",
    "#X_train = std.fit_transform(X_train)\n",
    "#X_test = std.fit_transform(X_test)\n",
    "#X_val = std.fit_transform(X_val)\n",
    "\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_val = y_val.reshape(-1, 1)\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.00000000001\n",
    "batch_size = 10\n",
    "num_epochs = 10\n",
    "\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 1\n",
    "\n",
    "########\n",
    "\n",
    "input_data = tf.keras.layers.Input(shape=(n_input,))\n",
    "x = tf.keras.layers.Dense(n_hidden1, activation=tf.nn.relu)(input_data)\n",
    "x = tf.keras.layers.Dense(n_hidden2, activation=tf.nn.relu)(x)\n",
    "output = tf.keras.layers.Dense(n_classes)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=tf.train.GradientDescentOptimizer(learning_rate=learning_rate),\n",
    "              metrics=['mean_squared_error'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=10,\n",
    "                    epochs=10,\n",
    "                    verbose=2,\n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "y_pred_proba = model.predict(X_test)[:,:]\n",
    "\n",
    "# 確率を0, 1に変換\n",
    "#y_pred = np.where(y_pred_proba >0.5, 1, 0)\n",
    "\n",
    "print(\"y_pred_proba\", y_pred_proba)\n",
    "#print(\"y_pred\", y_pred)\n",
    "#結果がいらず、評価のみ行う場合はevaluateメソッドも便利です。\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【問題5】MNISTをKerasで学習\n",
    "TensorFlowによるMNISTデータセットによる画像の多値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_29 (InputLayer)        [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 100)               5100      \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 45,360\n",
      "Trainable params: 45,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 38400 samples, validate on 9600 samples\n",
      "Epoch 1/10\n",
      "38400/38400 - 2s - loss: 0.2981 - acc: 0.9113 - val_loss: 0.2266 - val_acc: 0.9344\n",
      "Epoch 2/10\n",
      "38400/38400 - 1s - loss: 0.1575 - acc: 0.9521 - val_loss: 0.1860 - val_acc: 0.9454\n",
      "Epoch 3/10\n",
      "38400/38400 - 1s - loss: 0.1252 - acc: 0.9610 - val_loss: 0.1705 - val_acc: 0.9534\n",
      "Epoch 4/10\n",
      "38400/38400 - 1s - loss: 0.1153 - acc: 0.9657 - val_loss: 0.1621 - val_acc: 0.9530\n",
      "Epoch 5/10\n",
      "38400/38400 - 1s - loss: 0.1106 - acc: 0.9682 - val_loss: 0.1709 - val_acc: 0.9545\n",
      "Epoch 6/10\n",
      "38400/38400 - 1s - loss: 0.0965 - acc: 0.9714 - val_loss: 0.1753 - val_acc: 0.9583\n",
      "Epoch 7/10\n",
      "38400/38400 - 1s - loss: 0.0875 - acc: 0.9734 - val_loss: 0.1759 - val_acc: 0.9580\n",
      "Epoch 8/10\n",
      "38400/38400 - 1s - loss: 0.0851 - acc: 0.9743 - val_loss: 0.1840 - val_acc: 0.9565\n",
      "Epoch 9/10\n",
      "38400/38400 - 1s - loss: 0.0796 - acc: 0.9762 - val_loss: 0.1840 - val_acc: 0.9575\n",
      "Epoch 10/10\n",
      "38400/38400 - 1s - loss: 0.0775 - acc: 0.9772 - val_loss: 0.1880 - val_acc: 0.9592\n",
      "Test loss: 0.1773169451324599\n",
      "Test accuracy: 0.95966667\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TensorFlowで実装したニューラルネットワークを使いMNISTデータセットを3値分類する\n",
    "\"\"\"\n",
    "# データセットの読み込み\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 画像データを2次元に変換\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "#onehot\n",
    "enc = Oneenc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test = enc.fit_transform(y_test[:, np.newaxis])\n",
    "\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "\n",
    "# ハイパーパラメータの設定\n",
    "learning_rate = 0.05\n",
    "batch_size = 100\n",
    "num_epochs = 10\n",
    "\n",
    "n_hidden1 = 50\n",
    "n_hidden2 = 100\n",
    "n_input = X_train.shape[1]\n",
    "n_samples = X_train.shape[0]\n",
    "n_classes = 10\n",
    "\n",
    "\n",
    "input_data = tf.keras.layers.Input(shape=(n_input,))\n",
    "x = tf.keras.layers.Dense(n_hidden1, activation=tf.nn.relu)(input_data)\n",
    "x = tf.keras.layers.Dense(n_hidden2, activation=tf.nn.relu)(x)\n",
    "output = tf.keras.layers.Dense(n_classes, activation=tf.nn.softmax)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_data, outputs=output)\n",
    "\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.train.AdamOptimizer(learning_rate=0.01),\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=100,\n",
    "                    epochs=10,\n",
    "                    verbose=2,\n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "y_pred_proba = model.predict(X_test)[:,:]\n",
    "\n",
    "# 確率を0, 1に変換\n",
    "y_pred = np.where(y_pred_proba >0.5, 1, 0)\n",
    "\n",
    "#print(\"y_pred_proba\", y_pred_proba)\n",
    "#print(\"y_pred\", y_pred)\n",
    "#結果がいらず、評価のみ行う場合はevaluateメソッドも便利です。\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
